{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/joses-area/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.roi_measures import mad, ssim\n",
    "from utils.extraction import extract_patches\n",
    "from utils.reconstruction import perform_voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Activation, Input, PReLU, Flatten, Dense, Cropping3D, Dropout\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from keras.layers.convolutional import Conv3DTranspose as Deconv3D\n",
    "from keras.layers.core import Permute, Reshape\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "def generate_uresnet_model(input_shape, output_shape, num_classes=4, scale=1):\n",
    "    input = Input(shape=input_shape)\n",
    "\n",
    "    conv1 = get_res_conv_core(input, np.int32(scale*32))\n",
    "    pool1 = get_max_pooling_layer(conv1)\n",
    "\n",
    "    conv2 = get_res_conv_core(pool1, np.int32(scale*64))\n",
    "    pool2 = get_max_pooling_layer(conv2)\n",
    "\n",
    "    conv3 = get_res_conv_core(pool2, np.int32(scale*128))\n",
    "    pool3 = get_max_pooling_layer(conv3)\n",
    "\n",
    "    conv4 = get_res_conv_core(pool3, np.int32(scale*256))\n",
    "    \n",
    "    up1 = get_deconv_layer(conv4, np.int32(scale*128))\n",
    "    conv5 = get_res_conv_core(up1, np.int32(scale*128))\n",
    "\n",
    "    add35 = merge_add(conv3, conv5)\n",
    "    conv6 = get_res_conv_core(add35, np.int32(scale*128))\n",
    "    up2 = get_deconv_layer(conv6, np.int32(scale*64))\n",
    "\n",
    "    add22 = merge_add(conv2, up2)\n",
    "    conv7 = get_res_conv_core(add22, np.int32(scale*64))\n",
    "    up3 = get_deconv_layer(conv7, np.int32(scale*32))\n",
    "\n",
    "    add13 = merge_add(conv1, up3)\n",
    "    conv8 = get_res_conv_core(add13, np.int32(scale*32))\n",
    "\n",
    "    pred = get_conv_fc(conv8)\n",
    "    pred = organise_output(pred, output_shape)\n",
    "\n",
    "    return Model(inputs=[input], outputs=[pred])\n",
    "\n",
    "def merge_add(a, b) :\n",
    "    c = add([a, b])\n",
    "    c = BatchNormalization(axis=1)(c)\n",
    "    return PReLU()(c)\n",
    "\n",
    "def get_res_conv_core(input, num_filters) :\n",
    "    a = Conv3D(num_filters, kernel_size=(3, 3, 3), padding='same')(input)\n",
    "    b = Conv3D(num_filters, kernel_size=(1, 1, 1), padding='same')(input)\n",
    "    return merge_add(a, b)\n",
    "\n",
    "def get_max_pooling_layer(input) :\n",
    "    return MaxPooling3D(pool_size=(2, 2, 2))(input)\n",
    "\n",
    "def get_deconv_layer(input, num_filters) :\n",
    "    return Deconv3D(num_filters, kernel_size=(2, 2, 2), strides=(2, 2, 2))(input)\n",
    "\n",
    "def get_conv_fc(input, num_filters=4) :\n",
    "    fc = Conv3D(num_filters, kernel_size=(1, 1, 1))(input)\n",
    "\n",
    "    return PReLU()(fc)\n",
    "\n",
    "def organise_output(input, output_shape) :\n",
    "    pred = Reshape((4, 32*32*32))(input)\n",
    "    pred = Permute((2, 1))(pred)\n",
    "    return Activation('softmax')(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scale=1\n",
    "curr_patch_shape = (32, 32, 32)\n",
    "patch_shape = (1, ) + curr_patch_shape\n",
    "output_shape = (np.product(curr_patch_shape), 2)\n",
    "model = generate_uresnet_model(patch_shape, output_shape, scale)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_range = range(1, 100)\n",
    "np.random.shuffle(a_range)\n",
    "\n",
    "N = len(a_range)\n",
    "N_train = np.uint8(np.ceil(N * 0.70))\n",
    "\n",
    "range_train = a_range[:N_train]\n",
    "range_val = a_range[N_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 1->2 2->3 2 : 1->2 2->3 3->4 3 : 4 : 1->2 2->3 5 : 1->2 2->3 3->4 6 : 7 : 1->2 3->4 4->5 8 : 1->2 2->3 9 : 1->2 2->3 10 : 1->2 2->3 11 : 12 : 1->2 2->3 3->4 13 : 1->2 2->3 3->4 14 : 1->2 2->3 15 : 16 : 1->2 2->3 17 : 1->2 3->4 4->5 18 : 1->2 3->4 4->5 19 : 20 : 1->2 2->3 3->4 21 : 1->2 2->3 22 : 1->2 2->3 23 : 1->2 2->3 24 : 25 : 26 : 1->2 2->3 27 : 1->2 2->3 3->4 4->5 28 : 1->2 2->3 29 : 1->2 2->3 30 : 1->2 2->3 31 : 1->2 2->3 3->4 32 : 1->2 2->3 33 : 34 : 1->2 2->3 3->4 4->5 35 : 1->2 2->3 36 : 1->2 3->4 4->5 37 : 1->2 2->3 3->4 4->5 38 : 39 : 1->2 2->3 40 : 1->2 2->3 3->4 41 : 1->2 2->3 3->4 42 : 1->2 2->3 43 : 1->2 2->3 44 : 1->2 2->3 3->4 45 : 1->2 2->3 46 : 1->2 2->3 47 : 1->2 2->3 48 : 1->2 2->3 3->4 4->5 49 : 1->2 2->3 3->4 50 : 1->2 2->3 51 : 1->2 2->3 3->4 52 : 1->2 2->3 53 : 1->2 2->3 54 : 1->2 2->3 55 : 1->2 2->3 56 : 1->2 2->3 57 : 1->2 2->3 3->4 58 : 1->2 2->3 3->4 59 : 60 : 1->2 2->3 61 : 1->2 2->3 3->4 62 : 1->2 2->3 3->4 63 : 1->2 2->3 64 : 1->2 2->3 3->4 65 : 66 : 1->2 2->3 67 : 1->2 2->3 3->4 4->5 68 : 1->2 2->3 69 : 1->2 2->3 70 : 1->2 2->3 3->4 4->5 71 : 1->2 2->3 72 : 73 : 1->2 2->3 3->4 4->5 74 : 75 : 1->2 2->3 76 : 1->2 2->3 3->4 77 : 1->2 2->3 78 : 1->2 2->3 3->4 79 : 1->2 2->3 3->4 80 : 1->2 2->3 3->4 81 : 1->2 2->3 82 : 83 : 84 : 85 : 1->2 2->3 86 : 1->2 2->3 87 : 1->2 2->3 88 : 1->2 2->3 89 : 1->2 3->4 90 : 1->2 2->3 3->4 91 : 1->2 2->3 92 : 1->2 2->3 93 : 94 : 1->2 2->3 95 : 1->2 2->3 3->4 96 : 1->2 2->3 97 : 1->2 2->3 98 : 1->2 2->3 99 : 1->2 2->3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "file_general_pattern = 'OAS2_0{0:03}_MR{1}'\n",
    "dataset_skull_location = 'datasets/OASIS/OASIS2/SKULL/{}.nii.gz'\n",
    "dataset_histogram_location = 'datasets/OASIS/OASIS2/MATCHED_HISTOGRAM/{}.nii.gz'\n",
    "\n",
    "step = (16, 16, 16)\n",
    "num_classes = 4\n",
    "threshold = np.int32(0.40 * np.prod(curr_patch_shape[:]))\n",
    "ref_train = np.empty((0, 1, ) + curr_patch_shape)\n",
    "out_train = np.empty((0, np.prod(curr_patch_shape), num_classes))\n",
    "ref_val = np.empty((0, 1, ) + curr_patch_shape)\n",
    "out_val = np.empty((0, np.prod(curr_patch_shape), num_classes))\n",
    "for i in range(1, 100) :\n",
    "    print '{} :'.format(i),\n",
    "    \n",
    "    for j in range(1, 5) :\n",
    "        k = j + 1\n",
    "        filename = dataset_histogram_location.format(file_general_pattern.format(i, j))\n",
    "        seg_filename = dataset_skull_location.format(file_general_pattern.format(i, str(j)+ '_seg'))\n",
    "        \n",
    "        if not os.path.exists(filename) :\n",
    "            continue\n",
    "\n",
    "        volume_init = nib.load(filename).get_data()\n",
    "\n",
    "        mask_patches = extract_patches(volume_init != 0, curr_patch_shape, step)\n",
    "        useful_patches = np.sum(mask_patches, axis=(1, 2, 3)) > threshold\n",
    "        N = np.sum(useful_patches)\n",
    "        \n",
    "        del mask_patches\n",
    "\n",
    "        mov_patches = extract_patches(volume_init, curr_patch_shape, step)\n",
    "        mov_patches = mov_patches[useful_patches].reshape((-1, 1, ) + curr_patch_shape)\n",
    "        if i in range_train :\n",
    "            ref_train = np.vstack((mov_patches, ref_train)).astype('float32')\n",
    "        else :\n",
    "            ref_val = np.vstack((mov_patches, ref_val)).astype('float32')\n",
    "        del mov_patches\n",
    "\n",
    "        volume_init = nib.load(seg_filename).get_data()\n",
    "\n",
    "        mov_prob_patches = extract_patches(volume_init, curr_patch_shape, step)\n",
    "        mov_prob_patches = mov_prob_patches[useful_patches].reshape((-1, 1, np.prod(curr_patch_shape)))\n",
    "        \n",
    "        labels_train = np.empty((N, np.prod(curr_patch_shape), 4))\n",
    "        for l in range(N) :\n",
    "            labels_train[l] = to_categorical(mov_prob_patches[l].flatten(), 4)\n",
    "    \n",
    "        if i in range_train :\n",
    "            out_train = np.vstack((labels_train, out_train)).astype('float32')\n",
    "        else :\n",
    "            out_val = np.vstack((labels_train, out_val)).astype('float32')\n",
    "        del labels_train, mov_prob_patches\n",
    "        ######################################################################################\n",
    "        print '{}->{}'.format(j, k),\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_mean = ref_train.mean()\n",
    "train_std = ref_train.std()\n",
    "\n",
    "ref_train = (ref_train - train_mean) / train_std\n",
    "ref_val = (ref_val - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "786.1171 587.41235\n"
     ]
    }
   ],
   "source": [
    "print train_mean, train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 41651 samples, validate on 15018 samples\n",
      "Epoch 1/100\n",
      "41651/41651 [==============================] - 397s 10ms/step - loss: 0.0500 - acc: 0.9792 - val_loss: 0.0458 - val_acc: 0.9808\n",
      "Epoch 2/100\n",
      "41651/41651 [==============================] - 398s 10ms/step - loss: 0.0423 - acc: 0.9821 - val_loss: 0.0369 - val_acc: 0.9849\n",
      "Epoch 3/100\n",
      "41651/41651 [==============================] - 398s 10ms/step - loss: 0.0400 - acc: 0.9830 - val_loss: 0.0441 - val_acc: 0.9820\n",
      "Epoch 4/100\n",
      "41651/41651 [==============================] - 399s 10ms/step - loss: 0.0366 - acc: 0.9845 - val_loss: 0.0394 - val_acc: 0.9837\n",
      "Epoch 5/100\n",
      "41651/41651 [==============================] - 399s 10ms/step - loss: 0.0343 - acc: 0.9854 - val_loss: 0.0368 - val_acc: 0.9847\n",
      "Epoch 6/100\n",
      "41651/41651 [==============================] - 398s 10ms/step - loss: 0.0331 - acc: 0.9859 - val_loss: 0.0774 - val_acc: 0.9704\n",
      "Epoch 7/100\n",
      "41651/41651 [==============================] - 398s 10ms/step - loss: 0.0303 - acc: 0.9870 - val_loss: 0.0343 - val_acc: 0.9861\n",
      "Epoch 8/100\n",
      "41651/41651 [==============================] - 398s 10ms/step - loss: 0.0294 - acc: 0.9874 - val_loss: 0.0427 - val_acc: 0.9826\n",
      "Epoch 9/100\n",
      "41651/41651 [==============================] - 398s 10ms/step - loss: 0.0281 - acc: 0.9879 - val_loss: 0.0390 - val_acc: 0.9844\n",
      "Epoch 10/100\n",
      "41651/41651 [==============================] - 398s 10ms/step - loss: 0.0276 - acc: 0.9882 - val_loss: 0.0368 - val_acc: 0.9850\n",
      "Epoch 11/100\n",
      "41651/41651 [==============================] - 398s 10ms/step - loss: 0.0264 - acc: 0.9887 - val_loss: 0.0389 - val_acc: 0.9841\n",
      "Epoch 12/100\n",
      "41651/41651 [==============================] - 398s 10ms/step - loss: 0.0256 - acc: 0.9890 - val_loss: 0.0684 - val_acc: 0.9763\n",
      "Epoch 13/100\n",
      "41651/41651 [==============================] - 398s 10ms/step - loss: 0.0258 - acc: 0.9890 - val_loss: 0.0554 - val_acc: 0.9791\n",
      "Epoch 14/100\n",
      "41651/41651 [==============================] - 398s 10ms/step - loss: 0.0243 - acc: 0.9895 - val_loss: 0.0391 - val_acc: 0.9844\n",
      "Epoch 15/100\n",
      "41651/41651 [==============================] - 398s 10ms/step - loss: 0.0236 - acc: 0.9898 - val_loss: 0.0336 - val_acc: 0.9868\n",
      "Epoch 16/100\n",
      "41651/41651 [==============================] - 398s 10ms/step - loss: 0.0237 - acc: 0.9898 - val_loss: 0.0309 - val_acc: 0.9878\n",
      "Epoch 17/100\n",
      "41651/41651 [==============================] - 398s 10ms/step - loss: 0.0226 - acc: 0.9903 - val_loss: 0.0304 - val_acc: 0.9881\n",
      "Epoch 18/100\n",
      "41651/41651 [==============================] - 398s 10ms/step - loss: 0.0219 - acc: 0.9905 - val_loss: 0.0551 - val_acc: 0.9809\n",
      "Epoch 19/100\n",
      "41651/41651 [==============================] - 398s 10ms/step - loss: 0.0224 - acc: 0.9904 - val_loss: 0.1180 - val_acc: 0.9694\n",
      "Epoch 20/100\n",
      "41651/41651 [==============================] - 398s 10ms/step - loss: 0.0214 - acc: 0.9908 - val_loss: 0.0566 - val_acc: 0.9809\n",
      "Epoch 21/100\n",
      "41651/41651 [==============================] - 398s 10ms/step - loss: 0.0211 - acc: 0.9909 - val_loss: 0.0304 - val_acc: 0.9883\n",
      "Epoch 22/100\n",
      "41651/41651 [==============================] - 398s 10ms/step - loss: 0.0210 - acc: 0.9909 - val_loss: 0.0312 - val_acc: 0.9880\n",
      "Epoch 23/100\n",
      "41651/41651 [==============================] - 398s 10ms/step - loss: 0.0205 - acc: 0.9912 - val_loss: 0.0488 - val_acc: 0.9835\n",
      "Epoch 24/100\n",
      "41651/41651 [==============================] - 398s 10ms/step - loss: 0.0200 - acc: 0.9913 - val_loss: 0.0337 - val_acc: 0.9875\n",
      "Epoch 25/100\n",
      "41651/41651 [==============================] - 398s 10ms/step - loss: 0.0201 - acc: 0.9913 - val_loss: 0.0342 - val_acc: 0.9875\n",
      "Epoch 26/100\n",
      "41651/41651 [==============================] - 398s 10ms/step - loss: 0.0201 - acc: 0.9913 - val_loss: 0.0459 - val_acc: 0.9843\n",
      "Epoch 27/100\n",
      "41651/41651 [==============================] - 398s 10ms/step - loss: 0.0197 - acc: 0.9915 - val_loss: 0.0394 - val_acc: 0.9860\n",
      "Epoch 28/100\n",
      "41651/41651 [==============================] - 398s 10ms/step - loss: 0.0189 - acc: 0.9918 - val_loss: 0.0336 - val_acc: 0.9875\n",
      "Epoch 29/100\n",
      "41651/41651 [==============================] - 398s 10ms/step - loss: 0.0193 - acc: 0.9916 - val_loss: 0.0351 - val_acc: 0.9873\n",
      "Epoch 30/100\n",
      "41651/41651 [==============================] - 398s 10ms/step - loss: 0.0189 - acc: 0.9918 - val_loss: 0.0331 - val_acc: 0.9876\n",
      "Epoch 31/100\n",
      "41651/41651 [==============================] - 398s 10ms/step - loss: 0.0185 - acc: 0.9920 - val_loss: 0.0410 - val_acc: 0.9854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f60e4012c50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "patience = 10\n",
    "\n",
    "stopper = EarlyStopping(patience=patience)\n",
    "checkpointer = ModelCheckpoint('models/ag_segmenter.h5', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "N = len(ref_train)\n",
    "model.fit(\n",
    "    ref_train, out_train,\n",
    "    validation_data=(ref_val, out_val), epochs=100,\n",
    "    callbacks=[checkpointer, stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('models/ag_segmenter.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
