{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "from utils.extraction import extract_patches\n",
    "from unet import generate_uresnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 1\n",
    "patch_shape = (32, 32, 32)\n",
    "input_shape = (1, ) + patch_shape\n",
    "output_shape = (np.product(patch_shape), 4)\n",
    "model = generate_uresnet_model(input_shape, output_shape, scale)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1, 32, 32, 32 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 32, 32, 32, 3 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 32, 32, 32, 3 64          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 32, 3 0           conv3d_1[0][0]                   \n",
      "                                                                 conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 32, 3 128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_1 (PReLU)               (None, 32, 32, 32, 3 1048576     batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 32, 16, 16, 1 8224        p_re_lu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 16, 16, 1 128         conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_2 (PReLU)               (None, 32, 16, 16, 1 131072      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 64, 16, 16, 1 55360       p_re_lu_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, 64, 16, 16, 1 2112        p_re_lu_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 16, 16, 1 0           conv3d_4[0][0]                   \n",
      "                                                                 conv3d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 16, 16, 1 256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_3 (PReLU)               (None, 64, 16, 16, 1 262144      batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)               (None, 64, 8, 8, 8)  32832       p_re_lu_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 8, 8, 8)  256         conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_4 (PReLU)               (None, 64, 8, 8, 8)  32768       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 128, 8, 8, 8) 221312      p_re_lu_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, 128, 8, 8, 8) 8320        p_re_lu_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 8, 8, 8) 0           conv3d_7[0][0]                   \n",
      "                                                                 conv3d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 8, 8, 8) 512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_5 (PReLU)               (None, 128, 8, 8, 8) 65536       batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)               (None, 128, 4, 4, 4) 131200      p_re_lu_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 128, 4, 4, 4) 512         conv3d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_6 (PReLU)               (None, 128, 4, 4, 4) 8192        batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_10 (Conv3D)              (None, 256, 4, 4, 4) 884992      p_re_lu_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)              (None, 256, 4, 4, 4) 33024       p_re_lu_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 256, 4, 4, 4) 0           conv3d_10[0][0]                  \n",
      "                                                                 conv3d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 256, 4, 4, 4) 1024        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_7 (PReLU)               (None, 256, 4, 4, 4) 16384       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_1 (Conv3DTrans (None, 128, 8, 8, 8) 262272      p_re_lu_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)              (None, 128, 8, 8, 8) 442496      conv3d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)              (None, 128, 8, 8, 8) 16512       conv3d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 128, 8, 8, 8) 0           conv3d_12[0][0]                  \n",
      "                                                                 conv3d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 128, 8, 8, 8) 512         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_8 (PReLU)               (None, 128, 8, 8, 8) 65536       batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 128, 8, 8, 8) 0           p_re_lu_5[0][0]                  \n",
      "                                                                 p_re_lu_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 128, 8, 8, 8) 512         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_9 (PReLU)               (None, 128, 8, 8, 8) 65536       batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)              (None, 128, 8, 8, 8) 442496      p_re_lu_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_15 (Conv3D)              (None, 128, 8, 8, 8) 16512       p_re_lu_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 128, 8, 8, 8) 0           conv3d_14[0][0]                  \n",
      "                                                                 conv3d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 128, 8, 8, 8) 512         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_10 (PReLU)              (None, 128, 8, 8, 8) 65536       batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_2 (Conv3DTrans (None, 64, 16, 16, 1 65600       p_re_lu_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 64, 16, 16, 1 0           p_re_lu_3[0][0]                  \n",
      "                                                                 conv3d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 16, 16, 1 256         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_11 (PReLU)              (None, 64, 16, 16, 1 262144      batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_16 (Conv3D)              (None, 64, 16, 16, 1 110656      p_re_lu_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_17 (Conv3D)              (None, 64, 16, 16, 1 4160        p_re_lu_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 64, 16, 16, 1 0           conv3d_16[0][0]                  \n",
      "                                                                 conv3d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 16, 16, 1 256         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_12 (PReLU)              (None, 64, 16, 16, 1 262144      batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_3 (Conv3DTrans (None, 32, 32, 32, 3 16416       p_re_lu_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 32, 32, 32, 3 0           p_re_lu_1[0][0]                  \n",
      "                                                                 conv3d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 32, 3 128         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_13 (PReLU)              (None, 32, 32, 32, 3 1048576     batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_18 (Conv3D)              (None, 32, 32, 32, 3 27680       p_re_lu_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_19 (Conv3D)              (None, 32, 32, 32, 3 1056        p_re_lu_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 32, 32, 32, 3 0           conv3d_18[0][0]                  \n",
      "                                                                 conv3d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 32, 3 128         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_14 (PReLU)              (None, 32, 32, 32, 3 1048576     batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_20 (Conv3D)              (None, 4, 32, 32, 32 132         p_re_lu_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_15 (PReLU)              (None, 4, 32, 32, 32 131072      conv3d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 4, 32768)     0           p_re_lu_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 32768, 4)     0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32768, 4)     0           permute_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,303,236\n",
      "Trainable params: 7,300,676\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_range = range(1, 100)\n",
    "np.random.shuffle(a_range)\n",
    "\n",
    "N = len(a_range)\n",
    "N_train = np.uint8(np.ceil(N * 0.70))\n",
    "\n",
    "range_train = a_range[:N_train]\n",
    "range_val = a_range[N_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 : 1->2 2->3 1 : 1->2 2->3 35 : 1->2 2->3 75 : 1->2 2->3 86 : 1->2 2->3 92 : 1->2 2->3 36 : 1->2 3->4 4->5 34 : 1->2 2->3 3->4 4->5 89 : 1->2 3->4 14 : 1->2 2->3 9 : 1->2 2->3 16 : 1->2 2->3 73 : 1->2 2->3 3->4 4->5 43 : 1->2 2->3 19 : 94 : 1->2 2->3 32 : 1->2 2->3 99 : 1->2 2->3 74 : 61 : 1->2 2->3 3->4 20 : 1->2 2->3 3->4 84 : 53 : 1->2 2->3 8 : 1->2 2->3 6 : 17 : 1->2 3->4 4->5 90 : 1->2 2->3 3->4 87 : 1->2 2->3 31 : 1->2 2->3 3->4 47 : 1->2 2->3 82 : 60 : 1->2 2->3 88 : 1->2 2->3 42 : 1->2 2->3 77 : 1->2 2->3 22 : 1->2 2->3 72 : 49 : 1->2 2->3 3->4 97 : 1->2 2->3 96 : 1->2 2->3 40 : 1->2 2->3 3->4 95 : 1->2 2->3 3->4 76 : 1->2 2->3 3->4 91 : 1->2 2->3 85 : 1->2 2->3 46 : 1->2 2->3 57 : 1->2 2->3 3->4 25 : 62 : 1->2 2->3 3->4 13 : 1->2 2->3 3->4 37 : 1->2 2->3 3->4 4->5 38 : 21 : 1->2 2->3 66 : 1->2 2->3 78 : 1->2 2->3 3->4 56 : 1->2 2->3 2 : 1->2 2->3 3->4 59 : 98 : 1->2 2->3 15 : 67 : 1->2 2->3 3->4 4->5 3 : 71 : 1->2 2->3 33 : 26 : 1->2 2->3 45 : 1->2 2->3 64 : 1->2 2->3 3->4 55 : 1->2 2->3 52 : 1->2 2->3 24 : 11 : 28 : 1->2 2->3 10 : 1->2 2->3 30 : 1->2 2->3 68 : 1->2 2->3 79 : 1->2 2->3 3->4 41 : 1->2 2->3 3->4 18 : 1->2 3->4 4->5 39 : 1->2 2->3 65 : 80 : 1->2 2->3 3->4 12 : 1->2 2->3 3->4 93 : 44 : 1->2 2->3 3->4 5 : 1->2 2->3 3->4 7 : 1->2 3->4 4->5 81 : 1->2 2->3 63 : 1->2 2->3 27 : 1->2 2->3 3->4 4->5 83 : 29 : 1->2 2->3 50 : 1->2 2->3 23 : 1->2 2->3 54 : 1->2 2->3 51 : 1->2 2->3 3->4 48 : 1->2 2->3 3->4 4->5 69 : 1->2 2->3 58 : 1->2 2->3 3->4 70 : 1->2 2->3 3->4 4->5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "file_general_pattern = 'OAS2_0{0:03}_MR{1}'\n",
    "dataset_skull_location = '/mnt/harddisk/datasets/OASIS/SKULL/{}.nii.gz'\n",
    "dataset_histogram_location = '/mnt/harddisk/datasets/OASIS/MATCHED_HISTOGRAM/{}.nii.gz'\n",
    "\n",
    "step = (16, 16, 16)\n",
    "num_classes = 4\n",
    "threshold = np.int32(0.40 * np.prod(patch_shape[:]))\n",
    "ref_train = np.empty((0, 1, ) + patch_shape)\n",
    "out_train = np.empty((0, np.prod(patch_shape), num_classes))\n",
    "ref_val = np.empty((0, 1, ) + patch_shape)\n",
    "out_val = np.empty((0, np.prod(patch_shape), num_classes))\n",
    "for i in a_range :\n",
    "    print '{} :'.format(i),\n",
    "    \n",
    "    for j in range(1, 5) :\n",
    "        k = j + 1\n",
    "        filename = dataset_histogram_location.format(file_general_pattern.format(i, j))\n",
    "        seg_filename = dataset_skull_location.format(file_general_pattern.format(i, str(j)+ '_seg'))\n",
    "        \n",
    "        if not os.path.exists(filename) :\n",
    "            continue\n",
    "\n",
    "        volume_init = nib.load(filename).get_data()\n",
    "\n",
    "        mask_patches = extract_patches(volume_init != 0, patch_shape, step)\n",
    "        useful_patches = np.sum(mask_patches, axis=(1, 2, 3)) > threshold\n",
    "        N = np.sum(useful_patches)\n",
    "        \n",
    "        del mask_patches\n",
    "\n",
    "        mov_patches = extract_patches(volume_init, patch_shape, step)\n",
    "        mov_patches = mov_patches[useful_patches].reshape((-1, 1, ) + patch_shape)\n",
    "        if i in range_train :\n",
    "            ref_train = np.vstack((mov_patches, ref_train)).astype('float32')\n",
    "        else :\n",
    "            ref_val = np.vstack((mov_patches, ref_val)).astype('float32')\n",
    "        del mov_patches\n",
    "\n",
    "        volume_init = nib.load(seg_filename).get_data()\n",
    "\n",
    "        mov_prob_patches = extract_patches(volume_init, patch_shape, step)\n",
    "        mov_prob_patches = mov_prob_patches[useful_patches].reshape((-1, 1, np.prod(patch_shape)))\n",
    "        \n",
    "        labels_train = np.empty((N, np.prod(patch_shape), 4))\n",
    "        for l in range(N) :\n",
    "            labels_train[l] = to_categorical(mov_prob_patches[l].flatten(), 4)\n",
    "    \n",
    "        if i in range_train :\n",
    "            out_train = np.vstack((labels_train, out_train)).astype('float32')\n",
    "        else :\n",
    "            out_val = np.vstack((labels_train, out_val)).astype('float32')\n",
    "        del labels_train, mov_prob_patches\n",
    "        ######################################################################################\n",
    "        print '{}->{}'.format(j, k),\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_mean = ref_train.mean()\n",
    "train_std = ref_train.std()\n",
    "params = {'train_mean' : train_mean, 'train_std' : train_std}\n",
    "\n",
    "np.save('models/ag_segmenter_o1o2.npy', params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ref_train = (ref_train - train_mean) / train_std\n",
    "ref_val = (ref_val - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "789.9806 587.54895\n"
     ]
    }
   ],
   "source": [
    "print train_mean, train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38738 samples, validate on 17931 samples\n",
      "Epoch 1/100\n",
      "38738/38738 [==============================] - 429s 11ms/step - loss: 0.0997 - acc: 0.9637 - val_loss: 0.0696 - val_acc: 0.9702\n",
      "Epoch 2/100\n",
      "38738/38738 [==============================] - 416s 11ms/step - loss: 0.0498 - acc: 0.9794 - val_loss: 0.0448 - val_acc: 0.9813\n",
      "Epoch 3/100\n",
      "38738/38738 [==============================] - 413s 11ms/step - loss: 0.0428 - acc: 0.9821 - val_loss: 0.0508 - val_acc: 0.9796\n",
      "Epoch 4/100\n",
      "38738/38738 [==============================] - 412s 11ms/step - loss: 0.0377 - acc: 0.9841 - val_loss: 0.0545 - val_acc: 0.9774\n",
      "Epoch 5/100\n",
      "38738/38738 [==============================] - 413s 11ms/step - loss: 0.0345 - acc: 0.9854 - val_loss: 0.0365 - val_acc: 0.9850\n",
      "Epoch 6/100\n",
      "38738/38738 [==============================] - 412s 11ms/step - loss: 0.0323 - acc: 0.9863 - val_loss: 0.0715 - val_acc: 0.9744\n",
      "Epoch 7/100\n",
      "38738/38738 [==============================] - 413s 11ms/step - loss: 0.0293 - acc: 0.9876 - val_loss: 0.0570 - val_acc: 0.9780\n",
      "Epoch 8/100\n",
      "38738/38738 [==============================] - 413s 11ms/step - loss: 0.0292 - acc: 0.9877 - val_loss: 0.0489 - val_acc: 0.9814\n",
      "Epoch 9/100\n",
      "38738/38738 [==============================] - 414s 11ms/step - loss: 0.0284 - acc: 0.9880 - val_loss: 0.0353 - val_acc: 0.9858\n",
      "Epoch 10/100\n",
      "38738/38738 [==============================] - 414s 11ms/step - loss: 0.0256 - acc: 0.9891 - val_loss: 0.0373 - val_acc: 0.9853\n",
      "Epoch 11/100\n",
      "38738/38738 [==============================] - 414s 11ms/step - loss: 0.0246 - acc: 0.9895 - val_loss: 0.0345 - val_acc: 0.9867\n",
      "Epoch 12/100\n",
      "38738/38738 [==============================] - 414s 11ms/step - loss: 0.0242 - acc: 0.9897 - val_loss: 0.0407 - val_acc: 0.9850\n",
      "Epoch 13/100\n",
      "38738/38738 [==============================] - 414s 11ms/step - loss: 0.0232 - acc: 0.9901 - val_loss: 0.0597 - val_acc: 0.9797\n",
      "Epoch 14/100\n",
      "38738/38738 [==============================] - 414s 11ms/step - loss: 0.0225 - acc: 0.9904 - val_loss: 0.0368 - val_acc: 0.9857\n",
      "Epoch 15/100\n",
      "38738/38738 [==============================] - 414s 11ms/step - loss: 0.0216 - acc: 0.9908 - val_loss: 0.0375 - val_acc: 0.9862\n",
      "Epoch 16/100\n",
      "38738/38738 [==============================] - 414s 11ms/step - loss: 0.0214 - acc: 0.9909 - val_loss: 0.0388 - val_acc: 0.9852\n",
      "Epoch 17/100\n",
      "38738/38738 [==============================] - 414s 11ms/step - loss: 0.0203 - acc: 0.9913 - val_loss: 0.0374 - val_acc: 0.9864\n",
      "Epoch 18/100\n",
      "38738/38738 [==============================] - 415s 11ms/step - loss: 0.0205 - acc: 0.9912 - val_loss: 0.0381 - val_acc: 0.9861\n",
      "Epoch 19/100\n",
      "38738/38738 [==============================] - 415s 11ms/step - loss: 0.0201 - acc: 0.9914 - val_loss: 0.0387 - val_acc: 0.9862\n",
      "Epoch 20/100\n",
      "38738/38738 [==============================] - 414s 11ms/step - loss: 0.0197 - acc: 0.9916 - val_loss: 0.0426 - val_acc: 0.9843\n",
      "Epoch 21/100\n",
      "38738/38738 [==============================] - 414s 11ms/step - loss: 0.0194 - acc: 0.9917 - val_loss: 0.0391 - val_acc: 0.9859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f35102e9e50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "patience = 10\n",
    "\n",
    "stopper = EarlyStopping(patience=patience)\n",
    "checkpointer = ModelCheckpoint('models/ag_segmenter_o1o2.h5', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "N = len(ref_train)\n",
    "model.fit(\n",
    "    ref_train, out_train,\n",
    "    validation_data=(ref_val, out_val), epochs=100,\n",
    "    callbacks=[checkpointer, stopper])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
