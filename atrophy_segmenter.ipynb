{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/joses-area/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.roi_measures import mad, ssim\n",
    "from utils.extraction import extract_patches\n",
    "from utils.reconstruction import perform_voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Activation, Input, PReLU, Flatten, Dense, Cropping3D, Dropout\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from keras.layers.convolutional import Conv3DTranspose as Deconv3D\n",
    "from keras.layers.core import Permute, Reshape\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "def generate_uresnet_model(input_shape, output_shape, num_classes=4, scale=1):\n",
    "    input = Input(shape=input_shape)\n",
    "\n",
    "    conv1 = get_res_conv_core(input, np.int32(scale*32))\n",
    "    pool1 = get_max_pooling_layer(conv1)\n",
    "\n",
    "    conv2 = get_res_conv_core(pool1, np.int32(scale*64))\n",
    "    pool2 = get_max_pooling_layer(conv2)\n",
    "\n",
    "    conv3 = get_res_conv_core(pool2, np.int32(scale*128))\n",
    "    pool3 = get_max_pooling_layer(conv3)\n",
    "\n",
    "    conv4 = get_res_conv_core(pool3, np.int32(scale*256))\n",
    "    \n",
    "    up1 = get_deconv_layer(conv4, np.int32(scale*128))\n",
    "    conv5 = get_res_conv_core(up1, np.int32(scale*128))\n",
    "\n",
    "    add35 = merge_add(conv3, conv5)\n",
    "    conv6 = get_res_conv_core(add35, np.int32(scale*128))\n",
    "    up2 = get_deconv_layer(conv6, np.int32(scale*64))\n",
    "\n",
    "    add22 = merge_add(conv2, up2)\n",
    "    conv7 = get_res_conv_core(add22, np.int32(scale*64))\n",
    "    up3 = get_deconv_layer(conv7, np.int32(scale*32))\n",
    "\n",
    "    add13 = merge_add(conv1, up3)\n",
    "    conv8 = get_res_conv_core(add13, np.int32(scale*32))\n",
    "\n",
    "    pred = get_conv_fc(conv8)\n",
    "    pred = organise_output(pred, output_shape)\n",
    "\n",
    "    return Model(inputs=[input], outputs=[pred])\n",
    "\n",
    "def merge_add(a, b) :\n",
    "    c = add([a, b])\n",
    "    return Activation('relu')(c)\n",
    "\n",
    "def get_res_conv_core(input, num_filters) :\n",
    "    a = Conv3D(num_filters, kernel_size=(3, 3, 3), padding='same')(input)\n",
    "    b = Conv3D(num_filters, kernel_size=(1, 1, 1), padding='same')(input)\n",
    "    return merge_add(a, b)\n",
    "\n",
    "def get_max_pooling_layer(input) :\n",
    "    return MaxPooling3D(pool_size=(2, 2, 2))(input)\n",
    "\n",
    "def get_deconv_layer(input, num_filters) :\n",
    "    return Deconv3D(num_filters, kernel_size=(2, 2, 2), strides=(2, 2, 2))(input)\n",
    "\n",
    "def get_conv_fc(input, num_filters=4) :\n",
    "    fc = Conv3D(num_filters, kernel_size=(1, 1, 1))(input)\n",
    "\n",
    "    return Activation('relu')(fc)\n",
    "\n",
    "def organise_output(input, output_shape) :\n",
    "    pred = Reshape((4, 32*32*32))(input)\n",
    "    pred = Permute((2, 1))(pred)\n",
    "    return Activation('softmax')(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scale=0.5\n",
    "curr_patch_shape = (32, 32, 32)\n",
    "patch_shape = (1, ) + curr_patch_shape\n",
    "output_shape = (np.product(curr_patch_shape), 4)\n",
    "model = generate_uresnet_model(patch_shape, output_shape, scale)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 1->2 2 : 1->2 2->3 3 : 4 : 1->2 5 : 1->2 2->3 6 : 7 : 3->4 8 : 1->2 9 : 1->2 10 : 1->2 11 : 12 : 1->2 2->3 13 : 1->2 2->3 14 : 1->2 15 : 16 : 1->2 17 : 3->4 18 : 3->4 19 : 20 : 1->2 2->3 21 : 1->2 22 : 1->2 23 : 1->2 24 : 25 : 26 : 1->2 27 : 1->2 2->3 3->4 28 : 1->2 29 : 1->2 30 : 1->2 31 : 1->2 2->3 32 : 1->2 33 : 34 : 1->2 2->3 3->4 35 : 1->2 36 : 3->4 37 : 1->2 2->3 3->4 38 : 39 : 1->2 40 : 1->2 2->3 41 : 1->2 2->3 42 : 1->2 43 : 1->2 44 : 1->2 2->3 45 : 1->2 46 : 1->2 47 : 1->2 48 : 1->2 2->3 3->4 49 : 1->2 2->3 50 : 1->2 51 : 1->2 2->3 52 : 1->2 53 : 1->2 54 : 1->2 55 : 1->2 56 : 1->2 57 : 1->2 2->3 58 : 1->2 2->3 59 : 60 : 1->2 61 : 1->2 2->3 62 : 1->2 2->3 63 : 1->2 64 : 1->2 2->3 65 : 66 : 1->2 67 : 1->2 2->3 3->4 68 : 1->2 69 : 1->2 70 : 1->2 2->3 3->4 71 : 1->2 72 : 73 : 1->2 2->3 3->4 74 : 75 : 1->2 76 : 1->2 2->3 77 : 1->2 78 : 1->2 2->3 79 : 1->2 2->3 80 : 1->2 2->3 81 : 1->2 82 : 83 : 84 : 85 : 1->2 86 : 1->2 87 : 1->2 88 : 1->2 89 : 90 : 1->2 2->3 91 : 1->2 92 : 1->2 93 : 94 : 1->2 95 : 1->2 2->3 96 : 1->2 97 : 1->2 98 : 1->2 99 : 1->2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from medical_data import cdr_info, nwbv_info, diff_info\n",
    "\n",
    "file_general_pattern = 'OAS2_0{0:03}_MR{1}_{3}_OAS2_0{0:03}_MR{2}'\n",
    "dataset_location = 'datasets/OASIS/OASIS2/REG/{}/{}.nii.gz'\n",
    "\n",
    "step = (32, 32, 32)\n",
    "num_classes = 4\n",
    "threshold = np.int32(0.30 * np.prod(curr_patch_shape[:]))\n",
    "ref_train = np.empty((0, 1, ) + curr_patch_shape)\n",
    "out_train = np.empty((0, np.prod(curr_patch_shape), num_classes))\n",
    "for i in range(1, 100) :\n",
    "    print '{} :'.format(i),\n",
    "    \n",
    "    for j in range(1, 5) :\n",
    "        k = j + 1\n",
    "        mov_filename = dataset_location.format(\n",
    "            file_general_pattern.format(i, j, k, 'to'),\n",
    "            file_general_pattern.format(i, j, k, 'halfwayto'))\n",
    "        mov_prob_filename = dataset_location.format(\n",
    "            file_general_pattern.format(i, j, k, 'to'),\n",
    "            file_general_pattern.format(i, j, k, 'halfwayto') + '_brain_seg')\n",
    "\n",
    "        if not os.path.exists(mov_filename) :\n",
    "            continue\n",
    "\n",
    "        volume_init = nib.load(mov_filename).get_data()\n",
    "        volume_init = volume_init / volume_init.max()\n",
    "\n",
    "        mask_patches = extract_patches(volume_init != 0, curr_patch_shape, step)\n",
    "        useful_patches = np.sum(mask_patches, axis=(1, 2, 3)) > threshold\n",
    "        N = np.sum(useful_patches)\n",
    "        \n",
    "        del mask_patches\n",
    "\n",
    "        mov_patches = extract_patches(volume_init, curr_patch_shape, step)\n",
    "        mov_patches = mov_patches[useful_patches].reshape((-1, 1, ) + curr_patch_shape)\n",
    "        ref_train = np.vstack((mov_patches, ref_train)).astype('float32')\n",
    "        del mov_patches\n",
    "\n",
    "        volume_init = nib.load(mov_prob_filename).get_data()\n",
    "\n",
    "        mov_prob_patches = extract_patches(volume_init, curr_patch_shape, step)\n",
    "        mov_prob_patches = mov_prob_patches[useful_patches].reshape((-1, 1, np.prod(curr_patch_shape)))\n",
    "        \n",
    "        labels_train = np.empty((N, np.prod(curr_patch_shape), 4))\n",
    "        for l in range(N) :\n",
    "            labels_train[l] = to_categorical(mov_prob_patches[l].flatten(), 4)\n",
    "\n",
    "        out_train = np.vstack((labels_train, out_train)).astype('float32')\n",
    "        del labels_train, mov_prob_patches\n",
    "        ######################################################################################\n",
    "        print '{}->{}'.format(j, k),\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_mean = ref_train.mean()\n",
    "train_std = ref_train.std()\n",
    "\n",
    "ref_train = (ref_train - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23081103 0.18944699\n"
     ]
    }
   ],
   "source": [
    "print train_mean, train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4274 samples, validate on 1832 samples\n",
      "Epoch 1/40\n",
      "4274/4274 [==============================] - 24s 6ms/step - loss: 0.4159 - acc: 0.8354 - val_loss: 0.2521 - val_acc: 0.9004\n",
      "Epoch 2/40\n",
      "4274/4274 [==============================] - 24s 6ms/step - loss: 0.2174 - acc: 0.9151 - val_loss: 0.1819 - val_acc: 0.9299\n",
      "Epoch 3/40\n",
      "4274/4274 [==============================] - 24s 6ms/step - loss: 0.1684 - acc: 0.9344 - val_loss: 0.1801 - val_acc: 0.9268\n",
      "Epoch 4/40\n",
      "4274/4274 [==============================] - 24s 6ms/step - loss: 0.1497 - acc: 0.9417 - val_loss: 0.1421 - val_acc: 0.9425\n",
      "Epoch 5/40\n",
      "4274/4274 [==============================] - 24s 6ms/step - loss: 0.1420 - acc: 0.9442 - val_loss: 0.1403 - val_acc: 0.9428\n",
      "Epoch 6/40\n",
      "4274/4274 [==============================] - 24s 6ms/step - loss: 0.1312 - acc: 0.9486 - val_loss: 0.1360 - val_acc: 0.9444\n",
      "Epoch 7/40\n",
      "4274/4274 [==============================] - 24s 6ms/step - loss: 0.1222 - acc: 0.9521 - val_loss: 0.1215 - val_acc: 0.9511\n",
      "Epoch 8/40\n",
      "4274/4274 [==============================] - 24s 6ms/step - loss: 0.1158 - acc: 0.9545 - val_loss: 0.1194 - val_acc: 0.9518\n",
      "Epoch 9/40\n",
      "4274/4274 [==============================] - 24s 6ms/step - loss: 0.1074 - acc: 0.9571 - val_loss: 0.1081 - val_acc: 0.9555\n",
      "Epoch 10/40\n",
      "4274/4274 [==============================] - 24s 6ms/step - loss: 0.1064 - acc: 0.9567 - val_loss: 0.1075 - val_acc: 0.9549\n",
      "Epoch 11/40\n",
      "4274/4274 [==============================] - 24s 6ms/step - loss: 0.0989 - acc: 0.9588 - val_loss: 0.1227 - val_acc: 0.9496\n",
      "Epoch 12/40\n",
      "4274/4274 [==============================] - 24s 6ms/step - loss: 0.0965 - acc: 0.9595 - val_loss: 0.1045 - val_acc: 0.9566\n",
      "Epoch 13/40\n",
      "4274/4274 [==============================] - 24s 6ms/step - loss: 0.0904 - acc: 0.9621 - val_loss: 0.0997 - val_acc: 0.9579\n",
      "Epoch 14/40\n",
      "4274/4274 [==============================] - 24s 6ms/step - loss: 0.0907 - acc: 0.9618 - val_loss: 0.1102 - val_acc: 0.9531\n",
      "Epoch 15/40\n",
      "4274/4274 [==============================] - 24s 6ms/step - loss: 0.0885 - acc: 0.9627 - val_loss: 0.1085 - val_acc: 0.9551\n",
      "Epoch 16/40\n",
      "4274/4274 [==============================] - 24s 6ms/step - loss: 0.0818 - acc: 0.9655 - val_loss: 0.0952 - val_acc: 0.9599\n",
      "Epoch 17/40\n",
      "4274/4274 [==============================] - 23s 5ms/step - loss: 0.0792 - acc: 0.9667 - val_loss: 0.1120 - val_acc: 0.9531\n",
      "Epoch 18/40\n",
      "4274/4274 [==============================] - 23s 5ms/step - loss: 0.0763 - acc: 0.9679 - val_loss: 0.0931 - val_acc: 0.9606\n",
      "Epoch 19/40\n",
      "4274/4274 [==============================] - 24s 6ms/step - loss: 0.0757 - acc: 0.9681 - val_loss: 0.0957 - val_acc: 0.9598\n",
      "Epoch 20/40\n",
      "4274/4274 [==============================] - 24s 6ms/step - loss: 0.0766 - acc: 0.9676 - val_loss: 0.1336 - val_acc: 0.9474\n",
      "Epoch 21/40\n",
      "4274/4274 [==============================] - 24s 6ms/step - loss: 0.0725 - acc: 0.9696 - val_loss: 0.0905 - val_acc: 0.9624\n",
      "Epoch 22/40\n",
      "4274/4274 [==============================] - 23s 5ms/step - loss: 0.0735 - acc: 0.9692 - val_loss: 0.0933 - val_acc: 0.9614\n",
      "Epoch 23/40\n",
      "4274/4274 [==============================] - 23s 5ms/step - loss: 0.0689 - acc: 0.9710 - val_loss: 0.0970 - val_acc: 0.9603\n",
      "Epoch 24/40\n",
      "4274/4274 [==============================] - 24s 6ms/step - loss: 0.0658 - acc: 0.9724 - val_loss: 0.0947 - val_acc: 0.9617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca40ec3d90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "patience = 3\n",
    "\n",
    "stopper = EarlyStopping(patience=patience)\n",
    "checkpointer = ModelCheckpoint('models/ag_segmenter.h5', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "N = len(ref_train)\n",
    "model.fit(\n",
    "    ref_train, out_train,\n",
    "    validation_split=0.3, epochs=40,\n",
    "    callbacks=[checkpointer, stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('models/ag_segmenter.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
