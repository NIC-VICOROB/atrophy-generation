{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from extraction import extract_patches\n",
    "from reconstruction import perform_voting, generate_indexes\n",
    "\n",
    "from model import Multimodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 1 2\n",
      "2 : 1 2 3\n",
      "3 :\n",
      "4 : 1 2\n",
      "5 : 1 2 3\n",
      "6 :\n",
      "7 : 1 3 4\n",
      "8 : 1 2\n",
      "9 : 1 2\n",
      "10 : 1 2\n",
      "11 :\n",
      "12 : 1 2 3\n",
      "13 : 1 2 3\n",
      "14 : 1 2\n",
      "15 :\n",
      "16 : 1 2\n",
      "17 : 1 3 4 5\n",
      "18 : 1 3 4\n",
      "19 :\n",
      "20 : 1 2 3\n",
      "21 : 1 2\n",
      "22 : 1 2\n",
      "23 : 1 2\n",
      "24 :\n",
      "25 :\n",
      "26 : 1 2\n",
      "27 : 1 2 3 4\n",
      "28 : 1 2\n",
      "29 : 1 2\n",
      "30 : 1 2\n",
      "31 : 1 2 3\n",
      "32 : 1 2\n",
      "33 :\n",
      "34 : 1 2 3 4\n",
      "35 : 1 2\n",
      "36 : 1 3 4 5\n",
      "37 : 1 2 3 4\n",
      "38 :\n",
      "39 : 1 2\n",
      "40 : 1 2 3\n",
      "41 : 1 2 3\n",
      "42 : 1 2\n",
      "43 : 1 2\n",
      "44 : 1 2 3\n",
      "45 : 1 2\n",
      "46 : 1 2\n",
      "47 : 1 2\n",
      "48 : 1 2 3 4 5\n",
      "49 : 1 2 3\n",
      "50 : 1 2\n",
      "51 : 1 2 3\n",
      "52 : 1 2\n",
      "53 : 1 2\n",
      "54 : 1 2\n",
      "55 : 1 2\n",
      "56 : 1 2\n",
      "57 : 1 2 3\n",
      "58 : 1 2 3\n",
      "59 :\n",
      "60 : 1 2\n",
      "61 : 1 2 3\n",
      "62 : 1 2 3\n",
      "63 : 1 2\n",
      "64 : 1 2 3\n",
      "65 :\n",
      "66 : 1 2\n",
      "67 : 1 2 3 4\n",
      "68 : 1 2\n",
      "69 : 1 2\n",
      "70 : 1 2 3 4 5\n",
      "71 : 1 2\n",
      "72 :\n",
      "73 : 1 2 3 4 5\n",
      "74 :\n",
      "75 : 1 2\n",
      "76 : 1 2 3\n",
      "77 : 1 2\n",
      "78 : 1 2 3\n",
      "79 : 1 2 3\n",
      "80 : 1 2 3\n",
      "81 : 1 2\n",
      "82 :\n",
      "83 :\n",
      "84 :\n",
      "85 : 1 2\n",
      "86 : 1 2\n",
      "87 : 1 2\n",
      "88 : 1 2\n",
      "89 : 1 3\n",
      "90 : 1 2 3\n",
      "91 : 1 2\n",
      "92 : 1 2\n",
      "93 :\n",
      "94 : 1 2\n",
      "95 : 1 2 3\n",
      "96 : 1 2\n",
      "97 : 1 2\n",
      "98 : 1 2\n",
      "99 : 1 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "\n",
    "from medical_data import cdr_info, nwbv_info, diff_info\n",
    "\n",
    "orig_pattern = 'datasets/OASIS/OAS2_RAW_PART1/OAS2_00{0:02}_MR{1}/RAW/mpr-1_sstr_susan_matched.nii.gz'\n",
    "prob_pattern = 'datasets/OASIS/OAS2_RAW_PART1/OAS2_00{0:02}_MR{1}/RAW/mpr-1_sstr_susan_pve_{2}.nii.gz'\n",
    "\n",
    "step = (64, 64)\n",
    "threshold = np.int32(0.50 * np.prod(curr_patch_shape[:]))\n",
    "X_train = np.empty((0, 3, ) + curr_patch_shape)\n",
    "Y_train = np.empty((0, 1, ) + curr_patch_shape)\n",
    "for i in range(1, 100) :\n",
    "    print '{} :'.format(i),\n",
    "    for j in range(1, 6) :\n",
    "        filename = orig_pattern.format(i, j)\n",
    "        \n",
    "        if not os.path.exists(filename) :\n",
    "            continue\n",
    "\n",
    "        volume_init = nib.load(filename).get_data()\n",
    "        volume_mask = volume_init != 0\n",
    "        mask_patches = extract_patches(volume_mask, (1, ) + curr_patch_shape, (1, ) + step)\n",
    "        \n",
    "        useful_patches = np.sum(mask_patches, axis=(1, 2, 3)) > threshold\n",
    "        \n",
    "        N = np.sum(useful_patches)\n",
    "\n",
    "        volume_init = (volume_init - volume_init.mean()) / volume_init.std()\n",
    "\n",
    "        ref_patches = extract_patches(volume_init, (1, ) + curr_patch_shape, (1, ) + step)\n",
    "        ref_patches = ref_patches[useful_patches].reshape((-1, 1, ) + curr_patch_shape)\n",
    "        \n",
    "        Y_train = np.vstack((ref_patches, Y_train))\n",
    "        \n",
    "        del ref_patches\n",
    "        \n",
    "        new_patches = np.empty((N, 3, ) + curr_patch_shape)\n",
    "        for k in range(3) :\n",
    "            filename = prob_pattern.format(i, j, k)\n",
    "            prob_mask_init = nib.load(filename).get_data()\n",
    "            prob_patches = extract_patches(prob_mask_init, (1, ) + curr_patch_shape, (1, ) + step)\n",
    "            prob_patches = prob_patches[useful_patches].reshape((-1, ) + curr_patch_shape)\n",
    "            \n",
    "            new_patches[:, k] = prob_patches\n",
    "            \n",
    "            del prob_patches\n",
    "            \n",
    "        X_train = np.vstack((new_patches, X_train))\n",
    "        \n",
    "        del new_patches\n",
    "        \n",
    "        print j,\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent dimensions: 16\n",
      "Fuse latent representations using max\n",
      "making output: Tensor(\"enc_seg_act9_5/add:0\", shape=(?, 16, 128, 128), dtype=float32) Tensor(\"dec_Gen_18/dec_Gen_act5/add:0\", shape=(?, 1, 128, 128), dtype=float32) em_0_dec_Gen\n",
      "making output: Tensor(\"dropout_7/cond/Merge:0\", shape=(?, 16, 128, 128), dtype=float32) Tensor(\"dec_Gen_19/dec_Gen_act5/add:0\", shape=(?, 1, 128, 128), dtype=float32) em_1_dec_Gen\n",
      "making output: Tensor(\"combined_em_6/Maximum:0\", shape=(?, 16, 128, 128), dtype=float32) Tensor(\"dec_Gen_20/dec_Gen_act5/add:0\", shape=(?, 1, 128, 128), dtype=float32) em_2_dec_Gen\n",
      "making output: em_concat Tensor(\"em_concat_6/concat:0\", shape=(?, 2, ?), dtype=float32) em_concat_6/concat:0\n",
      "all outputs:  [u'em_0_dec_Gen_6/add:0', u'em_1_dec_Gen_6/add:0', u'em_2_dec_Gen_6/add:0', u'em_concat_6/concat:0', u'em_fused_6/ExpandDims:0']\n",
      "output dict:  {'em_concat': <function embedding_distance at 0x7f9caf0d55f0>, 'em_fused': <function embedding_distance at 0x7f9caf0d55f0>, 'em_1_dec_Gen': <function mean_absolute_error at 0x7f9f18f1c578>, 'em_0_dec_Gen': <function mean_absolute_error at 0x7f9f18f1c578>, 'em_2_dec_Gen': <function mean_absolute_error at 0x7f9f18f1c578>}\n",
      "loss weights:  {'em_concat': 1.0, 'em_fused': 0.0, 'em_1_dec_Gen': 1.0, 'em_0_dec_Gen': 1.0, 'em_2_dec_Gen': 1.0}\n"
     ]
    }
   ],
   "source": [
    "curr_patch_shape = (128, 128)\n",
    "input_modalities = ['seg', 'T1']\n",
    "output_modalities = ['Gen']\n",
    "output_weights = {'Gen' : 1.0, 'concat' : 1.0}\n",
    "latent_dim = 16\n",
    "channels = [3, 1]\n",
    "use_dropout = [False, True]\n",
    "patch_shape = curr_patch_shape\n",
    "scale = 1\n",
    "a_model = Multimodel(\n",
    "    input_modalities, output_modalities, output_weights, latent_dim, channels, patch_shape, use_dropout, scale)\n",
    "a_model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8618 samples, validate on 3694 samples\n",
      "Epoch 1/20\n",
      "8618/8618 [==============================] - 137s 16ms/step - loss: 0.4782 - em_0_dec_Gen_loss: 0.2034 - em_1_dec_Gen_loss: 0.1365 - em_2_dec_Gen_loss: 0.1194 - em_concat_loss: 0.0188 - em_fused_loss: 0.0000e+00 - val_loss: 0.5335 - val_em_0_dec_Gen_loss: 0.1586 - val_em_1_dec_Gen_loss: 0.1884 - val_em_2_dec_Gen_loss: 0.1827 - val_em_concat_loss: 0.0038 - val_em_fused_loss: 0.0000e+00\n",
      "Epoch 2/20\n",
      "8618/8618 [==============================] - 119s 14ms/step - loss: 0.2425 - em_0_dec_Gen_loss: 0.1290 - em_1_dec_Gen_loss: 0.0581 - em_2_dec_Gen_loss: 0.0489 - em_concat_loss: 0.0066 - em_fused_loss: 0.0000e+00 - val_loss: 0.5144 - val_em_0_dec_Gen_loss: 0.1408 - val_em_1_dec_Gen_loss: 0.2004 - val_em_2_dec_Gen_loss: 0.1708 - val_em_concat_loss: 0.0024 - val_em_fused_loss: 0.0000e+00\n",
      "Epoch 3/20\n",
      "8618/8618 [==============================] - 119s 14ms/step - loss: 0.2075 - em_0_dec_Gen_loss: 0.1138 - em_1_dec_Gen_loss: 0.0475 - em_2_dec_Gen_loss: 0.0411 - em_concat_loss: 0.0051 - em_fused_loss: 0.0000e+00 - val_loss: 0.5709 - val_em_0_dec_Gen_loss: 0.1363 - val_em_1_dec_Gen_loss: 0.2381 - val_em_2_dec_Gen_loss: 0.1947 - val_em_concat_loss: 0.0018 - val_em_fused_loss: 0.0000e+00\n",
      "Epoch 4/20\n",
      "8618/8618 [==============================] - 118s 14ms/step - loss: 0.1738 - em_0_dec_Gen_loss: 0.0997 - em_1_dec_Gen_loss: 0.0376 - em_2_dec_Gen_loss: 0.0323 - em_concat_loss: 0.0042 - em_fused_loss: 0.0000e+00 - val_loss: 0.5423 - val_em_0_dec_Gen_loss: 0.1337 - val_em_1_dec_Gen_loss: 0.2299 - val_em_2_dec_Gen_loss: 0.1773 - val_em_concat_loss: 0.0014 - val_em_fused_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9ca42a4ad0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "patience = 2\n",
    "\n",
    "stopper = EarlyStopping(patience=patience)\n",
    "checkpointer = ModelCheckpoint('model.h5', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "N = len(X_train)\n",
    "a_model.model.fit(\n",
    "    [X_train, Y_train],\n",
    "    [Y_train, Y_train, Y_train, np.empty((N, 2, 0)), np.empty((N, 1, 0))],\n",
    "    validation_split=0.3, epochs=20,\n",
    "    callbacks=[checkpointer, stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_model.model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "1280/1280 [==============================] - 9s 7ms/step\n",
      "99\n",
      "1280/1280 [==============================] - 8s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "import os\n",
    "import nibabel as nib\n",
    "import SimpleITK as sitk\n",
    "\n",
    "orig_pattern = 'datasets/OASIS/OAS2_RAW_PART1/OAS2_00{0:02}_MR{1}/RAW/mpr-1_sstr.nii.gz'\n",
    "prob_pattern = 'datasets/OASIS/OAS2_RAW_PART1/OAS2_00{0:02}_MR{1}/RAW/mpr-1_sstr_susan_pve_{2}.nii.gz'\n",
    "\n",
    "step = (32, 32)\n",
    "for i in range(98, 100) :\n",
    "    filename = orig_pattern.format(i, 1)\n",
    "    if not os.path.exists(filename) :\n",
    "        continue\n",
    "    \n",
    "    print i\n",
    "\n",
    "    volume_data = nib.load(filename)\n",
    "    volume_actual = volume_data.get_data()\n",
    "    volume_init = volume_actual != 0\n",
    "    ref_patches = extract_patches(volume_init, (1, ) + curr_patch_shape, (1, ) + step)\n",
    "    ref_patches = ref_patches.reshape((-1, 1, ) + curr_patch_shape)\n",
    "    \n",
    "    N = len(ref_patches)\n",
    "    new_patches = np.empty((N, 3, ) + curr_patch_shape)\n",
    "    for k in range(3) :\n",
    "        filename = prob_pattern.format(i, 1, k)\n",
    "        prob_mask_init = nib.load(filename).get_data()\n",
    "        prob_patches = extract_patches(prob_mask_init, (1, ) + curr_patch_shape, (1, ) + step)\n",
    "        prob_patches = prob_patches.reshape((-1, ) + curr_patch_shape)\n",
    "\n",
    "        new_patches[:, k] = prob_patches\n",
    "\n",
    "        del prob_patches\n",
    "    \n",
    "    pred = a_model.model.predict([new_patches, np.zeros_like(new_patches[:, 0:1, :, :])], verbose=1)[0]\n",
    "\n",
    "    volume = perform_voting(pred.reshape((-1, 1, ) + curr_patch_shape), (1, ) + curr_patch_shape, (256, 256, 128), (1, ) + step)\n",
    "    \n",
    "    volume[volume_actual != 0] = volume[volume_actual != 0] * volume_actual[volume_actual != 0].std() #+ volume_actual[volume_actual != 0].mean()\n",
    "    \n",
    "    volume = np.multiply(volume_data.get_data() != 0, volume)\n",
    "\n",
    "    nib.save(nib.Nifti1Image(volume, volume_data.affine), 'result_{}.nii.gz'.format(i))\n",
    "    \n",
    "    del new_patches, ref_patches\n",
    "    \n",
    "    res = sitk.ReadImage('result_{}.nii.gz'.format(i))\n",
    "\n",
    "    caster = sitk.CastImageFilter()\n",
    "    caster.SetOutputPixelType(res.GetPixelID())\n",
    "\n",
    "    orig = caster.Execute(sitk.ReadImage(orig_pattern.format(i, 1)))\n",
    "\n",
    "    matcher = sitk.HistogramMatchingImageFilter()\n",
    "    matcher.SetNumberOfHistogramLevels(1024)\n",
    "    matcher.SetNumberOfMatchPoints(15)\n",
    "    matched = matcher.Execute(res, orig)\n",
    "\n",
    "    sitk.WriteImage(matched, 'result_cor_{}.nii.gz'.format(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
