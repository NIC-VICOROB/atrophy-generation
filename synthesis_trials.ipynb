{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from extraction import extract_patches\n",
    "from reconstruction import perform_voting\n",
    "\n",
    "from model import Multimodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 1->2\n",
      "2 : 1->2 1->3 2->3\n",
      "3 :\n",
      "4 : 1->2\n",
      "5 : 1->3 2->3\n",
      "6 :\n",
      "7 : 1->3 1->4 3->4\n",
      "8 : 1->2\n",
      "9 : 1->2\n",
      "10 : 1->2\n",
      "11 :\n",
      "12 : 1->2 1->3 2->3\n",
      "13 : 1->3 2->3\n",
      "14 :\n",
      "15 :\n",
      "16 : 1->2\n",
      "17 : 1->3 1->4 1->5 3->5 4->5\n",
      "18 : 1->4 3->4\n",
      "19 :\n",
      "20 : 1->2 1->3 2->3\n",
      "21 : 1->2\n",
      "22 : 1->2\n",
      "23 : 1->2\n",
      "24 :\n",
      "25 :\n",
      "26 : 1->2\n",
      "27 : 1->3 1->4 2->3 2->4\n",
      "28 : 1->2\n",
      "29 :\n",
      "30 :\n",
      "31 : 1->3 2->3\n",
      "32 :\n",
      "33 :\n",
      "34 : 1->4 2->4 3->4\n",
      "35 :\n",
      "36 : 1->3 1->4 1->5 3->4 3->5 4->5\n",
      "37 : 1->2 1->3 1->4 2->3 2->4\n",
      "38 :\n",
      "39 : 1->2\n",
      "40 : 1->3 2->3\n",
      "41 : 1->3 2->3\n",
      "42 : 1->2\n",
      "43 : 1->2\n",
      "44 : 1->2 1->3\n",
      "45 : 1->2\n",
      "46 :\n",
      "47 :\n",
      "48 : 1->2 1->3 1->4 1->5 2->3 2->4 2->5 3->4 3->5 4->5\n",
      "49 :\n",
      "50 : 1->2\n",
      "51 : 1->2 1->3 2->3\n",
      "52 : 1->2\n",
      "53 : 1->2\n",
      "54 : 1->2\n",
      "55 : 1->2\n",
      "56 : 1->2\n",
      "57 : 1->3 2->3\n",
      "58 : 1->3 2->3\n",
      "59 :\n",
      "60 : 1->2\n",
      "61 : 1->2 1->3 2->3\n",
      "62 : 1->2 1->3 2->3\n",
      "63 : 1->2\n",
      "64 : 1->3 2->3\n",
      "65 :\n",
      "66 :\n",
      "67 : 1->2 1->3 1->4 2->3 2->4\n",
      "68 : 1->2\n",
      "69 :\n",
      "70 : 1->2 1->3 1->4 1->5 2->3 2->4 2->5 3->4 3->5\n",
      "71 : 1->2\n",
      "72 :\n",
      "73 : 1->2 1->3 1->4 1->5 2->3 2->4 2->5 3->4 3->5 4->5\n",
      "74 :\n",
      "75 :\n",
      "80 : 1->2 1->3 2->3\n",
      "81 : 1->2\n",
      "82 :\n",
      "83 :\n",
      "84 :\n",
      "85 :\n",
      "86 : 1->2\n",
      "87 : 1->2\n",
      "88 : 1->2\n",
      "89 : 1->3\n",
      "90 : 1->3 2->3\n",
      "91 : 1->2\n",
      "92 : 1->2\n",
      "93 :\n",
      "94 :\n",
      "95 : 1->2 1->3 2->3\n",
      "96 : 1->2\n",
      "97 : 1->2\n",
      "98 :\n",
      "99 : 1->2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "\n",
    "from medical_data import cdr_info, nwbv_info, diff_info\n",
    "\n",
    "orig_pattern = 'datasets/OASIS/OAS2_RAW_PART1/OAS2_00{0:02}_MR{1}/RAW/mpr-1_sstr_susan_matched.nii.gz'\n",
    "prob_pattern = 'datasets/OASIS/OAS2_RAW_PART1/OAS2_00{0:02}_MR{1}/RAW/mpr-1_sstr_susan_pve_{2}.nii.gz'\n",
    "\n",
    "step = (32, 32)\n",
    "threshold = np.int32(0.30 * np.prod(curr_patch_shape[:]))\n",
    "seg_train = np.empty((0, 1, ) + curr_patch_shape)\n",
    "ref_train = np.empty((0, 2, ) + curr_patch_shape)\n",
    "out_train = np.empty((0, 1, ) + curr_patch_shape)\n",
    "for i in np.append(range(1, 76), range(80, 100)) :\n",
    "    print '{} :'.format(i),\n",
    "    \n",
    "    for j in range(1, 6) :\n",
    "        ref_filename = orig_pattern.format(i, j)\n",
    "\n",
    "        if not os.path.exists(ref_filename) :\n",
    "            continue\n",
    "        \n",
    "        volume_init = nib.load(ref_filename).get_data()\n",
    "\n",
    "        mask_patches = extract_patches(volume_init != 0, (1, ) + curr_patch_shape, (1, ) + step)\n",
    "\n",
    "        useful_patches = np.sum(mask_patches, axis=(1, 2, 3)) > threshold\n",
    "\n",
    "        N = np.sum(useful_patches)\n",
    "\n",
    "        volume_init = (volume_init - volume_init.mean()) / volume_init.std()\n",
    "\n",
    "        ref_patches = extract_patches(volume_init, (1, ) + curr_patch_shape, (1, ) + step)\n",
    "        ref_patches = ref_patches[useful_patches].reshape((-1, 1, ) + curr_patch_shape)\n",
    "\n",
    "        ref_prob_patches = np.empty((N, 1, ) + curr_patch_shape)\n",
    "        for a in range(1) :\n",
    "            prob_filename = prob_pattern.format(i, j, a)\n",
    "            prob_mask_init = nib.load(prob_filename).get_data()\n",
    "            prob_patches = extract_patches(prob_mask_init, (1, ) + curr_patch_shape, (1, ) + step)\n",
    "            prob_patches = prob_patches[useful_patches].reshape((-1, ) + curr_patch_shape)\n",
    "\n",
    "            ref_prob_patches[:, a] = prob_patches\n",
    "\n",
    "            del prob_patches\n",
    "        \n",
    "        diff = 0\n",
    "        for k in range(j+1, 6) :\n",
    "            mov_filename = orig_pattern.format(i, k)\n",
    "\n",
    "            if not os.path.exists(mov_filename) :\n",
    "                continue\n",
    "    \n",
    "            diff = diff + diff_info['OAS2_00{0:02}_MR{1}'.format(i, k)]\n",
    "            if diff == 0 :\n",
    "                continue\n",
    "\n",
    "            volume_init = nib.load(mov_filename).get_data()\n",
    "            volume_init = (volume_init - volume_init.mean()) / volume_init.std()\n",
    "\n",
    "            mov_patches = extract_patches(volume_init, (1, ) + curr_patch_shape, (1, ) + step)\n",
    "            mov_patches = mov_patches[useful_patches].reshape((-1, 1, ) + curr_patch_shape)\n",
    "\n",
    "            ref_train = np.vstack((np.hstack((ref_patches, ref_prob_patches)), ref_train)) ##\n",
    "            out_train = np.vstack((mov_patches, out_train)) ##\n",
    "            del volume_init, mov_patches\n",
    "\n",
    "            mov_prob_patches = np.empty((N, 1, ) + curr_patch_shape)\n",
    "            for a in range(1) :\n",
    "                prob_filename = prob_pattern.format(i, k, a)\n",
    "                prob_mask_init = nib.load(prob_filename).get_data()\n",
    "                prob_patches = extract_patches(prob_mask_init, (1, ) + curr_patch_shape, (1, ) + step)\n",
    "                prob_patches = prob_patches[useful_patches].reshape((-1, ) + curr_patch_shape)\n",
    "\n",
    "                mov_prob_patches[:, a] = prob_patches\n",
    "\n",
    "                del prob_patches\n",
    "\n",
    "            seg_train = np.vstack((mov_prob_patches, seg_train)) ##\n",
    "            print '{}->{}'.format(j, k),\n",
    "            del mov_prob_patches\n",
    "        del ref_patches, ref_prob_patches\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent dimensions: 32\n",
      "Fuse latent representations using max\n",
      "making output: Tensor(\"enc_T1_act9_2/add:0\", shape=(?, 32, 128, 128), dtype=float32) Tensor(\"dec_Gen_6/dec_Gen_act5/add:0\", shape=(?, 1, 128, 128), dtype=float32) em_0_dec_Gen\n",
      "making output: Tensor(\"enc_seg_act9_2/add:0\", shape=(?, 32, 128, 128), dtype=float32) Tensor(\"dec_Gen_7/dec_Gen_act5/add:0\", shape=(?, 1, 128, 128), dtype=float32) em_1_dec_Gen\n",
      "making output: Tensor(\"combined_em_2/Maximum:0\", shape=(?, 32, 128, 128), dtype=float32) Tensor(\"dec_Gen_8/dec_Gen_act5/add:0\", shape=(?, 1, 128, 128), dtype=float32) em_2_dec_Gen\n",
      "making output: em_concat Tensor(\"em_concat_2/concat:0\", shape=(?, 2, ?), dtype=float32) em_concat_2/concat:0\n",
      "all outputs:  [u'em_0_dec_Gen_2/add:0', u'em_1_dec_Gen_2/add:0', u'em_2_dec_Gen_2/add:0', u'em_concat_2/concat:0', u'em_fused_2/ExpandDims:0']\n",
      "output dict:  {'em_concat': <function embedding_distance at 0x7fd94058e758>, 'em_fused': <function embedding_distance at 0x7fd94058e758>, 'em_1_dec_Gen': <function mean_absolute_error at 0x7fd94065b668>, 'em_0_dec_Gen': <function mean_absolute_error at 0x7fd94065b668>, 'em_2_dec_Gen': <function mean_absolute_error at 0x7fd94065b668>}\n",
      "loss weights:  {'em_concat': 1.0, 'em_fused': 0.0, 'em_1_dec_Gen': 1.0, 'em_0_dec_Gen': 1.0, 'em_2_dec_Gen': 1.0}\n"
     ]
    }
   ],
   "source": [
    "curr_patch_shape = (128, 128)\n",
    "input_modalities = ['T1', 'seg']\n",
    "output_modalities = ['Gen']\n",
    "output_weights = {'Gen' : 1.0, 'concat' : 1.0}\n",
    "latent_dim = 32\n",
    "channels = [2, 1]\n",
    "patch_shape = curr_patch_shape\n",
    "scale = 1\n",
    "a_model = Multimodel(\n",
    "    input_modalities, output_modalities, output_weights, latent_dim, channels, patch_shape, scale)\n",
    "a_model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38243 samples, validate on 16391 samples\n",
      "Epoch 1/20\n",
      "38243/38243 [==============================] - 573s 15ms/step - loss: 0.4244 - em_0_dec_Gen_loss: 0.1274 - em_1_dec_Gen_loss: 0.1879 - em_2_dec_Gen_loss: 0.1039 - em_concat_loss: 0.0052 - em_fused_loss: 0.0000e+00 - val_loss: 0.4064 - val_em_0_dec_Gen_loss: 0.1524 - val_em_1_dec_Gen_loss: 0.1489 - val_em_2_dec_Gen_loss: 0.1030 - val_em_concat_loss: 0.0021 - val_em_fused_loss: 0.0000e+00\n",
      "Epoch 2/20\n",
      "38243/38243 [==============================] - 567s 15ms/step - loss: 0.2835 - em_0_dec_Gen_loss: 0.1045 - em_1_dec_Gen_loss: 0.1046 - em_2_dec_Gen_loss: 0.0728 - em_concat_loss: 0.0015 - em_fused_loss: 0.0000e+00 - val_loss: 0.3981 - val_em_0_dec_Gen_loss: 0.1541 - val_em_1_dec_Gen_loss: 0.1440 - val_em_2_dec_Gen_loss: 0.0987 - val_em_concat_loss: 0.0013 - val_em_fused_loss: 0.0000e+00\n",
      "Epoch 3/20\n",
      "38243/38243 [==============================] - 567s 15ms/step - loss: 0.2550 - em_0_dec_Gen_loss: 0.0956 - em_1_dec_Gen_loss: 0.0931 - em_2_dec_Gen_loss: 0.0652 - em_concat_loss: 0.0011 - em_fused_loss: 0.0000e+00 - val_loss: 0.3926 - val_em_0_dec_Gen_loss: 0.1531 - val_em_1_dec_Gen_loss: 0.1408 - val_em_2_dec_Gen_loss: 0.0977 - val_em_concat_loss: 9.7693e-04 - val_em_fused_loss: 0.0000e+00\n",
      "Epoch 4/20\n",
      "38243/38243 [==============================] - 567s 15ms/step - loss: 0.2408 - em_0_dec_Gen_loss: 0.0903 - em_1_dec_Gen_loss: 0.0883 - em_2_dec_Gen_loss: 0.0614 - em_concat_loss: 8.5510e-04 - em_fused_loss: 0.0000e+00 - val_loss: 0.3928 - val_em_0_dec_Gen_loss: 0.1531 - val_em_1_dec_Gen_loss: 0.1410 - val_em_2_dec_Gen_loss: 0.0978 - val_em_concat_loss: 8.5665e-04 - val_em_fused_loss: 0.0000e+00\n",
      "Epoch 5/20\n",
      "38243/38243 [==============================] - 568s 15ms/step - loss: 0.2263 - em_0_dec_Gen_loss: 0.0864 - em_1_dec_Gen_loss: 0.0813 - em_2_dec_Gen_loss: 0.0579 - em_concat_loss: 7.4249e-04 - em_fused_loss: 0.0000e+00 - val_loss: 0.4002 - val_em_0_dec_Gen_loss: 0.1562 - val_em_1_dec_Gen_loss: 0.1413 - val_em_2_dec_Gen_loss: 0.1020 - val_em_concat_loss: 7.2225e-04 - val_em_fused_loss: 0.0000e+00\n",
      "Epoch 6/20\n",
      "38243/38243 [==============================] - 569s 15ms/step - loss: 0.2186 - em_0_dec_Gen_loss: 0.0842 - em_1_dec_Gen_loss: 0.0775 - em_2_dec_Gen_loss: 0.0562 - em_concat_loss: 6.5763e-04 - em_fused_loss: 0.0000e+00 - val_loss: 0.4263 - val_em_0_dec_Gen_loss: 0.1672 - val_em_1_dec_Gen_loss: 0.1467 - val_em_2_dec_Gen_loss: 0.1117 - val_em_concat_loss: 6.4777e-04 - val_em_fused_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd88bfb6610>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "patience = 3\n",
    "\n",
    "stopper = EarlyStopping(patience=patience)\n",
    "checkpointer = ModelCheckpoint('model.h5', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "N = len(ref_train)\n",
    "a_model.model.fit(\n",
    "    [ref_train, seg_train],\n",
    "    [out_train, out_train, out_train, np.empty((N, 2, 0)), np.empty((N, 1, 0))],\n",
    "    validation_split=0.3, epochs=20,\n",
    "    callbacks=[checkpointer, stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_model.model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "1280/1280 [==============================] - 11s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "import os\n",
    "import nibabel as nib\n",
    "import SimpleITK as sitk\n",
    "\n",
    "orig_pattern = 'datasets/OASIS/OAS2_RAW_PART1/OAS2_00{0:02}_MR{1}/RAW/mpr-1_sstr_susan_matched.nii.gz'\n",
    "prob_pattern = 'datasets/OASIS/OAS2_RAW_PART1/OAS2_00{0:02}_MR{1}/RAW/mpr-1_sstr_susan_pve_{2}.nii.gz'\n",
    "\n",
    "ref = 1\n",
    "mov = 3\n",
    "step = (32, 32)\n",
    "for i in range(78, 79) :\n",
    "    ref_filename = orig_pattern.format(i, ref)\n",
    "    mov_filename = orig_pattern.format(i, mov)\n",
    "    if not (os.path.exists(ref_filename) and os.path.exists(mov_filename)) :\n",
    "        continue\n",
    "    \n",
    "    print i\n",
    "\n",
    "    volume_data = nib.load(ref_filename)\n",
    "    volume_actual = volume_data.get_data()\n",
    "    volume_actual = (volume_actual - volume_actual.mean()) / volume_actual.std()\n",
    "    ref_patches = extract_patches(volume_actual, (1, ) + curr_patch_shape, (1, ) + step)\n",
    "    ref_patches = ref_patches.reshape((-1, 1, ) + curr_patch_shape)\n",
    "    \n",
    "    N = len(ref_patches)\n",
    "\n",
    "    old_patches = np.empty((N, 1, ) + curr_patch_shape)\n",
    "    for k in range(1) :\n",
    "        filename = prob_pattern.format(i, ref, k)\n",
    "        prob_mask_init = nib.load(filename).get_data()\n",
    "        prob_patches = extract_patches(prob_mask_init, (1, ) + curr_patch_shape, (1, ) + step)\n",
    "        prob_patches = prob_patches.reshape((-1, ) + curr_patch_shape)\n",
    "\n",
    "        old_patches[:, k] = prob_patches\n",
    "\n",
    "        del prob_patches\n",
    "    \n",
    "    new_patches = np.empty((N, 1, ) + curr_patch_shape)\n",
    "    for k in range(1) :\n",
    "        filename = prob_pattern.format(i, mov, k)\n",
    "        prob_mask_init = nib.load(filename).get_data()\n",
    "        prob_patches = extract_patches(prob_mask_init, (1, ) + curr_patch_shape, (1, ) + step)\n",
    "        prob_patches = prob_patches.reshape((-1, ) + curr_patch_shape)\n",
    "\n",
    "        new_patches[:, k] = prob_patches\n",
    "\n",
    "        del prob_patches\n",
    "    \n",
    "    pred = a_model.model.predict([np.hstack((ref_patches, old_patches)), new_patches], verbose=1)[2]\n",
    "\n",
    "    volume = perform_voting(pred.reshape((-1, 1, ) + curr_patch_shape), (1, ) + curr_patch_shape, (256, 256, 128), (1, ) + step)\n",
    "    \n",
    "    volume_data = nib.load(mov_filename)\n",
    "    volume_actual = volume_data.get_data()\n",
    "    volume = volume * volume_actual.std() + volume_actual.mean()\n",
    "    \n",
    "    volume = np.multiply(volume_data.get_data() != 0, volume)\n",
    "\n",
    "    nib.save(nib.Nifti1Image(volume, volume_data.affine), 'result_{}_{}_{}.nii.gz'.format(i, ref, mov))\n",
    "    \n",
    "    del new_patches, ref_patches\n",
    "    \n",
    "    res = sitk.ReadImage('result_{}_{}_{}.nii.gz'.format(i, ref, mov))\n",
    "\n",
    "    caster = sitk.CastImageFilter()\n",
    "    caster.SetOutputPixelType(res.GetPixelID())\n",
    "\n",
    "    orig = caster.Execute(sitk.ReadImage(orig_pattern.format(i, ref)))\n",
    "\n",
    "    matcher = sitk.HistogramMatchingImageFilter()\n",
    "    matcher.SetNumberOfHistogramLevels(1024)\n",
    "    matcher.SetNumberOfMatchPoints(15)\n",
    "    matched = matcher.Execute(res, orig)\n",
    "\n",
    "    sitk.WriteImage(matched, 'result_cor_{}_{}_{}.nii.gz'.format(i, ref, mov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "import os\n",
    "import nibabel as nib\n",
    "import SimpleITK as sitk\n",
    "\n",
    "orig_pattern = 'datasets/OASIS/OAS2_RAW_PART1/OAS2_00{0:02}_MR{1}/RAW/mpr-1_sstr_susan_matched.nii.gz'\n",
    "prob_pattern = 'datasets/OASIS/OAS2_RAW_PART1/OAS2_00{0:02}_MR{1}/RAW/mpr-1_sstr_susan_pve_{2}.nii.gz'\n",
    "\n",
    "ref = 1\n",
    "mov = 3\n",
    "step = (32, 32)\n",
    "for i in range(78, 79) :\n",
    "    ref_filename = orig_pattern.format(i, ref)\n",
    "    mov_filename = orig_pattern.format(i, mov)\n",
    "    if not (os.path.exists(ref_filename) and os.path.exists(mov_filename)) :\n",
    "        continue\n",
    "    \n",
    "    print i\n",
    "\n",
    "    volume_data = nib.load(ref_filename)\n",
    "    volume_actual = volume_data.get_data()\n",
    "    volume_actual = (volume_actual - volume_actual.mean()) / volume_actual.std()\n",
    "    ref_patches = extract_patches(volume_actual, (1, ) + curr_patch_shape, (1, ) + step)\n",
    "    ref_patches = ref_patches.reshape((-1, 1, ) + curr_patch_shape)\n",
    "    \n",
    "    N = len(ref_patches)\n",
    "\n",
    "    old_patches = np.empty((N, 1, ) + curr_patch_shape)\n",
    "    for k in range(1) :\n",
    "        filename = prob_pattern.format(i, ref, k)\n",
    "        prob_mask_init = nib.load(filename).get_data()\n",
    "        prob_patches = extract_patches(prob_mask_init, (1, ) + curr_patch_shape, (1, ) + step)\n",
    "        prob_patches = prob_patches.reshape((-1, ) + curr_patch_shape)\n",
    "\n",
    "        old_patches[:, k] = prob_patches\n",
    "\n",
    "        del prob_patches\n",
    "    \n",
    "    new_patches = np.empty((N, 1, ) + curr_patch_shape)\n",
    "    for k in range(1) :\n",
    "        filename = prob_pattern.format(i, mov, k)\n",
    "        prob_mask_init = nib.load(filename).get_data()\n",
    "        prob_patches = extract_patches(prob_mask_init, (1, ) + curr_patch_shape, (1, ) + step)\n",
    "        prob_patches = prob_patches.reshape((-1, ) + curr_patch_shape)\n",
    "\n",
    "        new_patches[:, k] = prob_patches\n",
    "\n",
    "        del prob_patches\n",
    "    \n",
    "    z = a_model.predict_z(input_modalities, [np.hstack((ref_patches, old_patches)), new_patches])[2]\n",
    "    \n",
    "    for z_i in range(z.shape[1]) :\n",
    "        volume = perform_voting(z[:, z_i, :, :].reshape((-1, 1, ) + curr_patch_shape), (1, ) + curr_patch_shape, (256, 256, 128), (1, ) + step)\n",
    "\n",
    "        volume_data = nib.load(mov_filename)\n",
    "        volume_actual = volume_data.get_data()\n",
    "        volume = volume * volume_actual.std() + volume_actual.mean()\n",
    "\n",
    "        volume = np.multiply(volume_data.get_data() != 0, volume)\n",
    "\n",
    "        nib.save(nib.Nifti1Image(volume, volume_data.affine), 'result_{}_{}_{}_{}.nii.gz'.format(i, ref, mov, z_i))\n",
    "\n",
    "    del new_patches, ref_patches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
