{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from extraction import extract_patches\n",
    "from reconstruction import perform_voting\n",
    "\n",
    "from model3d import Multimodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 1->2\n",
      "2 : 1->2 1->3 2->3\n",
      "3 :\n",
      "4 : 1->2\n",
      "5 : 1->3 2->3\n",
      "6 :\n",
      "7 : 1->3 1->4 3->4\n",
      "8 : 1->2\n",
      "9 : 1->2\n",
      "10 : 1->2\n",
      "11 :\n",
      "12 : 1->2 1->3 2->3\n",
      "13 : 1->3 2->3\n",
      "14 :\n",
      "15 :\n",
      "16 : 1->2\n",
      "17 : 1->3 1->4 1->5 3->5 4->5\n",
      "18 : 1->4 3->4\n",
      "19 :\n",
      "20 : 1->2 1->3 2->3\n",
      "21 : 1->2\n",
      "22 : 1->2\n",
      "23 : 1->2\n",
      "24 :\n",
      "25 :\n",
      "26 : 1->2\n",
      "27 : 1->3 1->4 2->3 2->4\n",
      "28 : 1->2\n",
      "29 :\n",
      "30 :\n",
      "31 : 1->3 2->3\n",
      "32 :\n",
      "33 :\n",
      "34 : 1->4 2->4 3->4\n",
      "35 :\n",
      "36 : 1->3 1->4 1->5 3->4 3->5 4->5\n",
      "37 : 1->2 1->3 1->4 2->3 2->4\n",
      "38 :\n",
      "39 : 1->2\n",
      "40 : 1->3 2->3\n",
      "41 : 1->3 2->3\n",
      "42 : 1->2\n",
      "43 : 1->2\n",
      "44 : 1->2 1->3\n",
      "45 : 1->2\n",
      "46 :\n",
      "47 :\n",
      "48 : 1->2 1->3 1->4 1->5 2->3 2->4 2->5 3->4 3->5 4->5\n",
      "49 :\n",
      "50 : 1->2\n",
      "51 : 1->2 1->3 2->3\n",
      "52 : 1->2\n",
      "53 : 1->2\n",
      "54 : 1->2\n",
      "55 : 1->2\n",
      "56 : 1->2\n",
      "57 : 1->3 2->3\n",
      "58 : 1->3 2->3\n",
      "59 :\n",
      "60 : 1->2\n",
      "61 : 1->2 1->3 2->3\n",
      "62 : 1->2 1->3 2->3\n",
      "63 : 1->2\n",
      "64 : 1->3 2->3\n",
      "65 :\n",
      "66 :\n",
      "67 : 1->2 1->3 1->4 2->3 2->4\n",
      "68 : 1->2\n",
      "69 :\n",
      "70 : 1->2 1->3 1->4 1->5 2->3 2->4 2->5 3->4 3->5\n",
      "71 : 1->2\n",
      "72 :\n",
      "73 : 1->2 1->3 1->4 1->5 2->3 2->4 2->5 3->4 3->5 4->5\n",
      "74 :\n",
      "75 :\n",
      "80 : 1->2 1->3 2->3\n",
      "81 : 1->2\n",
      "82 :\n",
      "83 :\n",
      "84 :\n",
      "85 :\n",
      "86 : 1->2\n",
      "87 : 1->2\n",
      "88 : 1->2\n",
      "89 : 1->3\n",
      "90 : 1->3 2->3\n",
      "91 : 1->2\n",
      "92 : 1->2\n",
      "93 :\n",
      "94 :\n",
      "95 : 1->2 1->3 2->3\n",
      "96 : 1->2\n",
      "97 : 1->2\n",
      "98 :\n",
      "99 : 1->2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "\n",
    "from medical_data import cdr_info, nwbv_info, diff_info\n",
    "\n",
    "orig_pattern = 'datasets/OASIS/OAS2_RAW_PART1/OAS2_00{0:02}_MR{1}/RAW/mpr-1_sstr_susan_matched.nii.gz'\n",
    "prob_pattern = 'datasets/OASIS/OAS2_RAW_PART1/OAS2_00{0:02}_MR{1}/RAW/mpr-1_sstr_susan_pve_{2}.nii.gz'\n",
    "\n",
    "step = (16, 16, 16)\n",
    "threshold = np.int32(0.30 * np.prod(curr_patch_shape[:]))\n",
    "seg_train = np.empty((0, 2, ) + curr_patch_shape)\n",
    "ref_train = np.empty((0, 2, ) + curr_patch_shape)\n",
    "out_train = np.empty((0, 1, ) + curr_patch_shape)\n",
    "for i in np.append(range(1, 76), range(80, 100)) :\n",
    "    print '{} :'.format(i),\n",
    "    \n",
    "    for j in range(1, 6) :\n",
    "        ref_filename = orig_pattern.format(i, j)\n",
    "\n",
    "        if not os.path.exists(ref_filename) :\n",
    "            continue\n",
    "        \n",
    "        volume_init = nib.load(ref_filename).get_data()\n",
    "\n",
    "        mask_patches = extract_patches(volume_init != 0, curr_patch_shape, step)\n",
    "\n",
    "        useful_patches = np.sum(mask_patches, axis=(1, 2, 3)) > threshold\n",
    "\n",
    "        N = np.sum(useful_patches)\n",
    "\n",
    "#         volume_init = (volume_init - volume_init.mean()) / volume_init.std()\n",
    "        volume_init = volume_init / volume_init.max()\n",
    "\n",
    "        ref_patches = extract_patches(volume_init, curr_patch_shape, step)\n",
    "        ref_patches = ref_patches[useful_patches].reshape((-1, 1, ) + curr_patch_shape)\n",
    "\n",
    "        ref_prob_patches = np.empty((N, 1, ) + curr_patch_shape)\n",
    "        for a in range(1) :\n",
    "            prob_filename = prob_pattern.format(i, j, a)\n",
    "            prob_mask_init = nib.load(prob_filename).get_data()\n",
    "            prob_patches = extract_patches(prob_mask_init, curr_patch_shape, step)\n",
    "            prob_patches = prob_patches[useful_patches].reshape((-1, ) + curr_patch_shape)\n",
    "\n",
    "            ref_prob_patches[:, a] = prob_patches\n",
    "\n",
    "            del prob_patches\n",
    "        \n",
    "        diff = 0\n",
    "        for k in range(j+1, 6) :\n",
    "            mov_filename = orig_pattern.format(i, k)\n",
    "\n",
    "            if not os.path.exists(mov_filename) :\n",
    "                continue\n",
    "    \n",
    "            diff = diff + diff_info['OAS2_00{0:02}_MR{1}'.format(i, k)]\n",
    "            if diff == 0 :\n",
    "                continue\n",
    "\n",
    "            volume_init = nib.load(mov_filename).get_data()\n",
    "#             volume_init = (volume_init - volume_init.mean()) / volume_init.std()\n",
    "            volume_init = volume_init / volume_init.max()\n",
    "\n",
    "            mov_patches = extract_patches(volume_init, curr_patch_shape, step)\n",
    "            mov_patches = mov_patches[useful_patches].reshape((-1, 1, ) + curr_patch_shape)\n",
    "\n",
    "            ref_train = np.vstack((np.hstack((ref_patches, ref_prob_patches)), ref_train)) ##\n",
    "            out_train = np.vstack((mov_patches, out_train)) ##\n",
    "\n",
    "            mov_prob_patches = np.empty((N, 1, ) + curr_patch_shape)\n",
    "            for a in range(1) :\n",
    "                prob_filename = prob_pattern.format(i, k, a)\n",
    "                prob_mask_init = nib.load(prob_filename).get_data()\n",
    "                prob_patches = extract_patches(prob_mask_init, curr_patch_shape, step)\n",
    "                prob_patches = prob_patches[useful_patches].reshape((-1, ) + curr_patch_shape)\n",
    "\n",
    "                mov_prob_patches[:, a] = prob_patches\n",
    "\n",
    "                del prob_patches\n",
    "\n",
    "            seg_train = np.vstack((np.hstack((mov_prob_patches, mov_patches != 0)), seg_train)) ##\n",
    "            print '{}->{}'.format(j, k),\n",
    "            del volume_init, mov_patches, mov_prob_patches\n",
    "        del ref_patches, ref_prob_patches\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent dimensions: 16\n",
      "Fuse latent representations using max\n",
      "making output: Tensor(\"enc_T1_act9_2/add:0\", shape=(?, 16, 32, 32, 32), dtype=float32) Tensor(\"dec_Gen_6/dec_Gen_act5/add:0\", shape=(?, 1, 32, 32, 32), dtype=float32) em_0_dec_Gen\n",
      "making output: Tensor(\"enc_seg_act9_2/add:0\", shape=(?, 16, 32, 32, 32), dtype=float32) Tensor(\"dec_Gen_7/dec_Gen_act5/add:0\", shape=(?, 1, 32, 32, 32), dtype=float32) em_1_dec_Gen\n",
      "making output: Tensor(\"combined_em_2/Maximum:0\", shape=(?, 16, 32, 32, 32), dtype=float32) Tensor(\"dec_Gen_8/dec_Gen_act5/add:0\", shape=(?, 1, 32, 32, 32), dtype=float32) em_2_dec_Gen\n",
      "making output: em_concat Tensor(\"em_concat_2/concat:0\", shape=(?, 2, ?), dtype=float32) em_concat_2/concat:0\n",
      "all outputs:  [u'em_0_dec_Gen_2/add:0', u'em_1_dec_Gen_2/add:0', u'em_2_dec_Gen_2/add:0', u'em_concat_2/concat:0', u'em_fused_2/ExpandDims:0']\n",
      "output dict:  {'em_concat': <function embedding_distance at 0x7ff70c185f50>, 'em_fused': <function embedding_distance at 0x7ff70c185f50>, 'em_1_dec_Gen': <function mean_absolute_error at 0x7ff777edc500>, 'em_0_dec_Gen': <function mean_absolute_error at 0x7ff777edc500>, 'em_2_dec_Gen': <function mean_absolute_error at 0x7ff777edc500>}\n",
      "loss weights:  {'em_concat': 1.0, 'em_fused': 0.0, 'em_1_dec_Gen': 1.0, 'em_0_dec_Gen': 1.0, 'em_2_dec_Gen': 1.0}\n"
     ]
    }
   ],
   "source": [
    "curr_patch_shape = (32, 32, 32)\n",
    "input_modalities = ['T1', 'seg']\n",
    "output_modalities = ['Gen']\n",
    "output_weights = {'Gen' : 1.0, 'concat' : 1.0}\n",
    "latent_dim = 16\n",
    "channels = [2, 2]\n",
    "patch_shape = curr_patch_shape\n",
    "scale = 0.5\n",
    "a_model = Multimodel(\n",
    "    input_modalities, output_modalities, output_weights, latent_dim, channels, patch_shape, scale)\n",
    "a_model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32201 samples, validate on 13801 samples\n",
      "Epoch 1/40\n",
      "32201/32201 [==============================] - 1021s 32ms/step - loss: 0.0919 - em_0_dec_Gen_loss: 0.0309 - em_1_dec_Gen_loss: 0.0354 - em_2_dec_Gen_loss: 0.0238 - em_concat_loss: 0.0017 - em_fused_loss: 0.0000e+00 - val_loss: 0.0864 - val_em_0_dec_Gen_loss: 0.0365 - val_em_1_dec_Gen_loss: 0.0272 - val_em_2_dec_Gen_loss: 0.0216 - val_em_concat_loss: 9.8749e-04 - val_em_fused_loss: 0.0000e+00\n",
      "Epoch 2/40\n",
      "32201/32201 [==============================] - 1014s 32ms/step - loss: 0.0714 - em_0_dec_Gen_loss: 0.0277 - em_1_dec_Gen_loss: 0.0246 - em_2_dec_Gen_loss: 0.0182 - em_concat_loss: 8.6802e-04 - em_fused_loss: 0.0000e+00 - val_loss: 0.0823 - val_em_0_dec_Gen_loss: 0.0362 - val_em_1_dec_Gen_loss: 0.0248 - val_em_2_dec_Gen_loss: 0.0205 - val_em_concat_loss: 7.5222e-04 - val_em_fused_loss: 0.0000e+00\n",
      "Epoch 3/40\n",
      "32201/32201 [==============================] - 1014s 31ms/step - loss: 0.0663 - em_0_dec_Gen_loss: 0.0269 - em_1_dec_Gen_loss: 0.0221 - em_2_dec_Gen_loss: 0.0167 - em_concat_loss: 6.2015e-04 - em_fused_loss: 0.0000e+00 - val_loss: 0.0800 - val_em_0_dec_Gen_loss: 0.0359 - val_em_1_dec_Gen_loss: 0.0241 - val_em_2_dec_Gen_loss: 0.0195 - val_em_concat_loss: 5.5344e-04 - val_em_fused_loss: 0.0000e+00\n",
      "Epoch 4/40\n",
      "32201/32201 [==============================] - 1013s 31ms/step - loss: 0.0640 - em_0_dec_Gen_loss: 0.0266 - em_1_dec_Gen_loss: 0.0209 - em_2_dec_Gen_loss: 0.0160 - em_concat_loss: 5.0013e-04 - em_fused_loss: 0.0000e+00 - val_loss: 0.0792 - val_em_0_dec_Gen_loss: 0.0359 - val_em_1_dec_Gen_loss: 0.0235 - val_em_2_dec_Gen_loss: 0.0194 - val_em_concat_loss: 4.6442e-04 - val_em_fused_loss: 0.0000e+00\n",
      "Epoch 5/40\n",
      "32201/32201 [==============================] - 1014s 31ms/step - loss: 0.0620 - em_0_dec_Gen_loss: 0.0261 - em_1_dec_Gen_loss: 0.0200 - em_2_dec_Gen_loss: 0.0155 - em_concat_loss: 4.3076e-04 - em_fused_loss: 0.0000e+00 - val_loss: 0.0782 - val_em_0_dec_Gen_loss: 0.0358 - val_em_1_dec_Gen_loss: 0.0229 - val_em_2_dec_Gen_loss: 0.0191 - val_em_concat_loss: 4.1551e-04 - val_em_fused_loss: 0.0000e+00\n",
      "Epoch 6/40\n",
      "32201/32201 [==============================] - 1013s 31ms/step - loss: 0.0598 - em_0_dec_Gen_loss: 0.0252 - em_1_dec_Gen_loss: 0.0192 - em_2_dec_Gen_loss: 0.0150 - em_concat_loss: 3.9332e-04 - em_fused_loss: 0.0000e+00 - val_loss: 0.0787 - val_em_0_dec_Gen_loss: 0.0362 - val_em_1_dec_Gen_loss: 0.0227 - val_em_2_dec_Gen_loss: 0.0195 - val_em_concat_loss: 3.5271e-04 - val_em_fused_loss: 0.0000e+00\n",
      "Epoch 7/40\n",
      "32201/32201 [==============================] - 1018s 32ms/step - loss: 0.0583 - em_0_dec_Gen_loss: 0.0250 - em_1_dec_Gen_loss: 0.0185 - em_2_dec_Gen_loss: 0.0145 - em_concat_loss: 3.4871e-04 - em_fused_loss: 0.0000e+00 - val_loss: 0.0774 - val_em_0_dec_Gen_loss: 0.0356 - val_em_1_dec_Gen_loss: 0.0225 - val_em_2_dec_Gen_loss: 0.0190 - val_em_concat_loss: 3.2836e-04 - val_em_fused_loss: 0.0000e+00\n",
      "Epoch 8/40\n",
      " 2112/32201 [>.............................] - ETA: 13:52 - loss: 0.0574 - em_0_dec_Gen_loss: 0.0240 - em_1_dec_Gen_loss: 0.0186 - em_2_dec_Gen_loss: 0.0145 - em_concat_loss: 3.2925e-04 - em_fused_loss: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6b0081d45897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mout_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     callbacks=[checkpointer, stopper])\n\u001b[0m",
      "\u001b[0;32m/home/jose/joses-area/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1646\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1648\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/jose/joses-area/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jose/joses-area/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2352\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jose/joses-area/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jose/joses-area/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jose/joses-area/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jose/joses-area/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jose/joses-area/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "patience = 3\n",
    "\n",
    "stopper = EarlyStopping(patience=patience)\n",
    "checkpointer = ModelCheckpoint('model3d_scale.h5', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "N = len(ref_train)\n",
    "a_model.model.fit(\n",
    "    [ref_train, seg_train],\n",
    "    [out_train, out_train, out_train, np.empty((N, 2, 0)), np.empty((N, 1, 0))],\n",
    "    validation_split=0.3, epochs=40,\n",
    "    callbacks=[checkpointer, stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_model.model.load_weights('model3d_scale.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mad(A, B) :\n",
    "    intersect = np.multiply(A != 0, B != 0)\n",
    "    max_a = A[intersect].max()\n",
    "    max_b = B[intersect].max()\n",
    "    return np.median(np.abs(A[intersect] / max_a - B[intersect] / max_b))\n",
    "\n",
    "def ssim(A_, B_) :\n",
    "    A = A_ / A_.max()\n",
    "    B = B_ / B_.max()\n",
    "    intersect = np.multiply(A != 0, B != 0)\n",
    "    ua = A[intersect].mean()\n",
    "    ub = B[intersect].mean()\n",
    "    oa = A[intersect].std() ** 2\n",
    "    ob = B[intersect].std() ** 2\n",
    "    oab = np.sum(np.multiply(A[intersect] - ua, B[intersect] - ub)) / (np.sum(intersect) - 1)\n",
    "    k1 = 0.01\n",
    "    k2 = 0.03\n",
    "    L = 1\n",
    "    c1 = (k1 * L) ** 2\n",
    "    c2 = (k2 * L) ** 2\n",
    "    num = (2*ua*ub + c1) * (2*oab + c2)\n",
    "    den = (ua**2 + ub**2 + c1) * (oa + ob + c2)\n",
    "    return num / den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "1575/1575 [==============================] - 20s 13ms/step\n",
      "(0.0197167442233, 0.013776384873), (0.979091372243, 0.988337120898)\n",
      "78\n",
      "1575/1575 [==============================] - 21s 13ms/step\n",
      "(0.0276124552513, 0.018205392612), (0.92525002193, 0.975855081903)\n",
      "79\n",
      "1575/1575 [==============================] - 20s 13ms/step\n",
      "(0.106200546878, 0.0396980511872), (0.484370017645, 0.914625512096)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "import os\n",
    "import nibabel as nib\n",
    "import SimpleITK as sitk\n",
    "\n",
    "orig_pattern = 'datasets/OASIS/OAS2_RAW_PART1/OAS2_00{0:02}_MR{1}/RAW/mpr-1_sstr_susan_matched.nii.gz'\n",
    "prob_pattern = 'datasets/OASIS/OAS2_RAW_PART1/OAS2_00{0:02}_MR{1}/RAW/mpr-1_sstr_susan_pve_{2}.nii.gz'\n",
    "\n",
    "ref = 1\n",
    "mov = 3\n",
    "step = (16, 16, 16)\n",
    "for i in range(76, 80) :\n",
    "    ref_filename = orig_pattern.format(i, ref)\n",
    "    mov_filename = orig_pattern.format(i, mov)\n",
    "    if not (os.path.exists(ref_filename) and os.path.exists(mov_filename)) :\n",
    "        continue\n",
    "    \n",
    "    print i\n",
    "\n",
    "    volume_data = nib.load(ref_filename)\n",
    "    volume_actual = volume_data.get_data()\n",
    "    volume_actual = volume_actual / volume_actual.max()\n",
    "    ref_patches = extract_patches(volume_actual, curr_patch_shape, step)\n",
    "    ref_patches = ref_patches.reshape((-1, 1, ) + curr_patch_shape)\n",
    "    \n",
    "    N = len(ref_patches)\n",
    "\n",
    "    old_patches = np.empty((N, 1, ) + curr_patch_shape)\n",
    "    for k in range(1) :\n",
    "        filename = prob_pattern.format(i, ref, k)\n",
    "        prob_mask_init = nib.load(filename).get_data()\n",
    "        prob_patches = extract_patches(prob_mask_init, curr_patch_shape, step)\n",
    "        prob_patches = prob_patches.reshape((-1, ) + curr_patch_shape)\n",
    "\n",
    "        old_patches[:, k] = prob_patches\n",
    "\n",
    "        del prob_patches\n",
    "    \n",
    "    volume_data = nib.load(mov_filename)\n",
    "    volume_actual = volume_data.get_data() != 0\n",
    "    mov_patches = extract_patches(volume_actual, curr_patch_shape, step)\n",
    "    mov_patches = mov_patches.reshape((-1, 1, ) + curr_patch_shape)\n",
    "    \n",
    "    new_patches = np.empty((N, 1, ) + curr_patch_shape)\n",
    "    for k in range(1) :\n",
    "        filename = prob_pattern.format(i, mov, k)\n",
    "        prob_mask_init = nib.load(filename).get_data()\n",
    "        prob_patches = extract_patches(prob_mask_init, curr_patch_shape, step)\n",
    "        prob_patches = prob_patches.reshape((-1, ) + curr_patch_shape)\n",
    "\n",
    "        new_patches[:, k] = prob_patches\n",
    "\n",
    "        del prob_patches\n",
    "    \n",
    "    pred = a_model.model.predict([np.hstack((ref_patches, old_patches)), np.hstack((new_patches, mov_patches))], verbose=1)[2]\n",
    "    pred = pred.reshape((-1, ) + curr_patch_shape)\n",
    "    \n",
    "    del new_patches, ref_patches\n",
    "    \n",
    "    volume = perform_voting(pred, curr_patch_shape, (256, 256, 128), step)\n",
    "    \n",
    "    volume_data = nib.load(mov_filename)\n",
    "    volume_actual = volume_data.get_data()\n",
    "    volume = volume * volume_actual.max()\n",
    "    \n",
    "    volume = np.multiply(volume_actual != 0, volume)\n",
    "\n",
    "    nib.save(nib.Nifti1Image(volume, volume_data.affine), 'results/result3d_{}_{}_{}.nii.gz'.format(i, ref, mov))\n",
    "      \n",
    "    res = sitk.ReadImage('results/result3d_{}_{}_{}.nii.gz'.format(i, ref, mov))\n",
    "\n",
    "    caster = sitk.CastImageFilter()\n",
    "    caster.SetOutputPixelType(res.GetPixelID())\n",
    "\n",
    "    orig = caster.Execute(sitk.ReadImage(orig_pattern.format(i, ref)))\n",
    "\n",
    "    matcher = sitk.HistogramMatchingImageFilter()\n",
    "    matcher.SetNumberOfHistogramLevels(1024)\n",
    "    matcher.SetNumberOfMatchPoints(15)\n",
    "    matched = matcher.Execute(res, orig)\n",
    "\n",
    "    sitk.WriteImage(matched, 'results/result3d_cor_{}_{}_{}.nii.gz'.format(i, ref, mov))\n",
    "    \n",
    "    volume = nib.load('results/result3d_cor_{}_{}_{}.nii.gz'.format(i, ref, mov)).get_data()\n",
    "    ref_vol = np.float64(nib.load(ref_filename).get_data())\n",
    "    mse_refgen = mad(volume, ref_vol)\n",
    "    ssim_refgen = ssim(volume, ref_vol)\n",
    "    mse_movgen = mad(volume, volume_actual)\n",
    "    ssim_movgen = ssim(volume, np.float64(volume_actual))\n",
    "    \n",
    "    print '({}, {}), ({}, {})'.format(mse_refgen, mse_movgen, ssim_refgen, ssim_movgen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
